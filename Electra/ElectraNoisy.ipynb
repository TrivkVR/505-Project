{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aa301d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad277587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May  3 17:14:42 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:3B:00.0 Off |                    0 |\r\n",
      "| N/A   36C    P0    24W / 250W |      0MiB / 16160MiB |      0%   E. Process |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:D8:00.0 Off |                    0 |\r\n",
      "| N/A   37C    P0    25W / 250W |      0MiB / 16160MiB |      0%   E. Process |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0aea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GPU\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18484685",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqq transformers datasets wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ffb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-5\n",
    "SEED = 4222\n",
    "\n",
    "MODEL_SAVE_PATH = \"Model_2/electra\"\n",
    "MODEL_CHECKPOINT_PATH = \"Model_2/electra_checkpoint\"\n",
    "MODEL_LOGGING_PATH = \"Model_2/electra_checkpoint/logs\"\n",
    "\n",
    "# WANDB_ENTITY = \"gohjiayi\"\n",
    "# WANDB_PROJECT = \"suicide_detection\"\n",
    "# WANDB_RUN = \"electra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faad65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2b7798",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('full_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee221d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>musical awareness: great big beautiful tomorro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>kapan sih lo ngebuktiin,jan ngomong doang susa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>show your love for your local field &amp; it might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>can you tell me when an update for the apple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>the crown, filthy mcnastys, katy dalys or the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Polarity                                               text\n",
       "0           0         1  musical awareness: great big beautiful tomorro...\n",
       "1           1         0  kapan sih lo ngebuktiin,jan ngomong doang susa...\n",
       "2           2         1  show your love for your local field & it might...\n",
       "3           3         1   can you tell me when an update for the apple ...\n",
       "4           4         1   the crown, filthy mcnastys, katy dalys or the..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec71bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation and test sets\n",
    "train, val = train_test_split(df,\n",
    "                               random_state=SEED,\n",
    "                               test_size=0.2,\n",
    "                               stratify=df['Polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a36a910b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bf85df09d5433fa3ed082c8cf32bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee9c295ae1845e79ce5e7c6e68fbe70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c9ef77356a4700a7928a22f408ddb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98bd8637488476399ca9daa0fbaaa7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load ELECTRA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\", do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d24f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b125177d33704b42bfe4932ecf4d968c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/51.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Import ELECTRA-base pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google/electra-small-discriminator\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "729474eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_conversion(train, test, val):\n",
    "  \"\"\"Converts pandas dataframe to Dataset.\"\"\"\n",
    "\n",
    "  train.reset_index(drop=True, inplace=True)\n",
    "  test.reset_index(drop=True, inplace=True)\n",
    "  val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "  train_dataset = Dataset.from_pandas(train)\n",
    "  test_dataset = Dataset.from_pandas(test)\n",
    "  val_dataset = Dataset.from_pandas(val)\n",
    "\n",
    "  return DatasetDict({\"train\": train_dataset,\n",
    "                      \"test\": test_dataset,\n",
    "                      \"val\": val_dataset})\n",
    "\n",
    "raw_datasets = dataset_conversion(train, test, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12bbd7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837534220d1f430b92492319563d59f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1280 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6ef12c8aef4804832f3fe7802a71a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec24f64b479c49c48b53679404ef5160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(dataset):\n",
    "    return tokenizer(dataset[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6ac92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise datasets\n",
    "SAMPLE_SIZE = 20\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "small_val_dataset = tokenized_datasets[\"val\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "\n",
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_test_dataset = tokenized_datasets[\"test\"]\n",
    "full_val_dataset = tokenized_datasets[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b217dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = full_train_dataset.rename_column(\"Polarity\", \"label\")\n",
    "full_test_dataset = full_test_dataset.rename_column(\"Polarity\", \"label\")\n",
    "full_val_dataset = full_val_dataset.rename_column(\"Polarity\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa9579ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom metrics for computation\n",
    "def compute_metrics(eval_pred):\n",
    "    metric_acc = load_metric(\"accuracy\")\n",
    "    metric_rec = load_metric(\"recall\")\n",
    "    metric_pre = load_metric(\"precision\")\n",
    "    metric_f1 = load_metric(\"f1\")\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = metric_acc.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    recall = metric_rec.compute(predictions=predictions, references=labels)[\"recall\"]\n",
    "    precision = metric_pre.compute(predictions=predictions, references=labels)[\"precision\"]\n",
    "    f1 = metric_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"recall\": recall, \"precision\": precision, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4ff86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d203291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Define model and training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_CHECKPOINT_PATH,\n",
    "    overwrite_output_dir = True,\n",
    "#     report_to = 'wandb',\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    logging_dir=MODEL_LOGGING_PATH,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1500\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_train_dataset,\n",
    "    eval_dataset=full_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed7f9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea7d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr4/cs505/orawal/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1279999\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 200000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162921' max='200000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [162921/200000 10:15:40 < 2:20:07, 4.41 it/s, Epoch 4.07/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.598600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.488700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.447600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.435600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.416700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.405400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.409500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.405700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.402500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.388700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.392900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.392800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.392100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.389300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.384900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.385100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.384700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.382100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.381800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.372800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.383400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.379400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.381100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.368100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.382300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.360600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.369300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.368700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.367400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.367800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.366600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.367100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.361900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.367900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.361100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.362200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.366200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.359700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.360200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.361700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.357400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.358300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.359500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.356700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.353200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.356100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.365100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.355900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.358300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.349700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.351100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.348800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.352600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.355800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.356600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.338500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.337600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.340200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.350500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.346100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>0.341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>0.348900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.345500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>0.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.342600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.347100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>0.340600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>0.344400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.344600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>0.341900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.338600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>0.345200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.336800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>0.340700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.334100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>0.332600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.338300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>0.346400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>0.341900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.327600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>0.341300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.337700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>0.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.333500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.344400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>0.338300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>0.335000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.334700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>0.335000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.343100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>0.332700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.331900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63500</td>\n",
       "      <td>0.337200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64500</td>\n",
       "      <td>0.332900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.334300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65500</td>\n",
       "      <td>0.337400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.335400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66500</td>\n",
       "      <td>0.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.329800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>0.342600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.347100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68500</td>\n",
       "      <td>0.335300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.333400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69500</td>\n",
       "      <td>0.330100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70500</td>\n",
       "      <td>0.333800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.337400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71500</td>\n",
       "      <td>0.327900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.332700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>0.335100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73500</td>\n",
       "      <td>0.334900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.336100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74500</td>\n",
       "      <td>0.329800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75500</td>\n",
       "      <td>0.332300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.330700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76500</td>\n",
       "      <td>0.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>0.340700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>0.330800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.335900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78500</td>\n",
       "      <td>0.327100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>0.335900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79500</td>\n",
       "      <td>0.333600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80500</td>\n",
       "      <td>0.324200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>0.325300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81500</td>\n",
       "      <td>0.327500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.321300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82500</td>\n",
       "      <td>0.325300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>0.317900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83500</td>\n",
       "      <td>0.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84500</td>\n",
       "      <td>0.319100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85500</td>\n",
       "      <td>0.314100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.324100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86500</td>\n",
       "      <td>0.323900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>0.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87500</td>\n",
       "      <td>0.329400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>0.319100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88500</td>\n",
       "      <td>0.316900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89000</td>\n",
       "      <td>0.328400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89500</td>\n",
       "      <td>0.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.318600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90500</td>\n",
       "      <td>0.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91000</td>\n",
       "      <td>0.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91500</td>\n",
       "      <td>0.322600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>0.320400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92500</td>\n",
       "      <td>0.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93000</td>\n",
       "      <td>0.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93500</td>\n",
       "      <td>0.315300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>0.321700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94500</td>\n",
       "      <td>0.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>0.323100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95500</td>\n",
       "      <td>0.319300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>0.330100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96500</td>\n",
       "      <td>0.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97000</td>\n",
       "      <td>0.328400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97500</td>\n",
       "      <td>0.322100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>0.324800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98500</td>\n",
       "      <td>0.322600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99000</td>\n",
       "      <td>0.316000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99500</td>\n",
       "      <td>0.320200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.326400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100500</td>\n",
       "      <td>0.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101000</td>\n",
       "      <td>0.312900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101500</td>\n",
       "      <td>0.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>0.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102500</td>\n",
       "      <td>0.319500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103000</td>\n",
       "      <td>0.325100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103500</td>\n",
       "      <td>0.328000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>0.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104500</td>\n",
       "      <td>0.330100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>0.321900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105500</td>\n",
       "      <td>0.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>0.325500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106500</td>\n",
       "      <td>0.325900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107000</td>\n",
       "      <td>0.320100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107500</td>\n",
       "      <td>0.315000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>0.318400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108500</td>\n",
       "      <td>0.321100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109000</td>\n",
       "      <td>0.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109500</td>\n",
       "      <td>0.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.315600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110500</td>\n",
       "      <td>0.327400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111000</td>\n",
       "      <td>0.324800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111500</td>\n",
       "      <td>0.322600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>0.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112500</td>\n",
       "      <td>0.316300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113000</td>\n",
       "      <td>0.324200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113500</td>\n",
       "      <td>0.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>0.319300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114500</td>\n",
       "      <td>0.315200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>0.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115500</td>\n",
       "      <td>0.318600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116000</td>\n",
       "      <td>0.322600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116500</td>\n",
       "      <td>0.324300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117000</td>\n",
       "      <td>0.313800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117500</td>\n",
       "      <td>0.315000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118000</td>\n",
       "      <td>0.323500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118500</td>\n",
       "      <td>0.315600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119000</td>\n",
       "      <td>0.319300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119500</td>\n",
       "      <td>0.318400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120500</td>\n",
       "      <td>0.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121000</td>\n",
       "      <td>0.308500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121500</td>\n",
       "      <td>0.305500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122000</td>\n",
       "      <td>0.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122500</td>\n",
       "      <td>0.315100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123000</td>\n",
       "      <td>0.311600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123500</td>\n",
       "      <td>0.316100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124000</td>\n",
       "      <td>0.305200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124500</td>\n",
       "      <td>0.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>0.309300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125500</td>\n",
       "      <td>0.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>0.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126500</td>\n",
       "      <td>0.310800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127000</td>\n",
       "      <td>0.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127500</td>\n",
       "      <td>0.307200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128000</td>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128500</td>\n",
       "      <td>0.307100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129000</td>\n",
       "      <td>0.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129500</td>\n",
       "      <td>0.303800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.310500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130500</td>\n",
       "      <td>0.307100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131000</td>\n",
       "      <td>0.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131500</td>\n",
       "      <td>0.314700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132000</td>\n",
       "      <td>0.303400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132500</td>\n",
       "      <td>0.310600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133000</td>\n",
       "      <td>0.314200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133500</td>\n",
       "      <td>0.313800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134000</td>\n",
       "      <td>0.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134500</td>\n",
       "      <td>0.312600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>0.314500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135500</td>\n",
       "      <td>0.310900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136000</td>\n",
       "      <td>0.309900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136500</td>\n",
       "      <td>0.313400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137000</td>\n",
       "      <td>0.302200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137500</td>\n",
       "      <td>0.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138000</td>\n",
       "      <td>0.316100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138500</td>\n",
       "      <td>0.311800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139000</td>\n",
       "      <td>0.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139500</td>\n",
       "      <td>0.310500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.309400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140500</td>\n",
       "      <td>0.316900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141000</td>\n",
       "      <td>0.311200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141500</td>\n",
       "      <td>0.311600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142000</td>\n",
       "      <td>0.314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142500</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143000</td>\n",
       "      <td>0.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143500</td>\n",
       "      <td>0.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144000</td>\n",
       "      <td>0.316900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144500</td>\n",
       "      <td>0.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>0.309400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145500</td>\n",
       "      <td>0.310700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146000</td>\n",
       "      <td>0.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146500</td>\n",
       "      <td>0.310300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147000</td>\n",
       "      <td>0.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147500</td>\n",
       "      <td>0.304500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148000</td>\n",
       "      <td>0.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148500</td>\n",
       "      <td>0.315600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149000</td>\n",
       "      <td>0.306600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149500</td>\n",
       "      <td>0.317200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>0.312300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150500</td>\n",
       "      <td>0.306900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151000</td>\n",
       "      <td>0.314100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151500</td>\n",
       "      <td>0.315000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152000</td>\n",
       "      <td>0.310200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152500</td>\n",
       "      <td>0.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153000</td>\n",
       "      <td>0.307700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153500</td>\n",
       "      <td>0.318000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154000</td>\n",
       "      <td>0.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154500</td>\n",
       "      <td>0.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>0.308800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155500</td>\n",
       "      <td>0.310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156000</td>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156500</td>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157000</td>\n",
       "      <td>0.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157500</td>\n",
       "      <td>0.316400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158000</td>\n",
       "      <td>0.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158500</td>\n",
       "      <td>0.308500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159000</td>\n",
       "      <td>0.312600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159500</td>\n",
       "      <td>0.304300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>0.315400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160500</td>\n",
       "      <td>0.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161000</td>\n",
       "      <td>0.300400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161500</td>\n",
       "      <td>0.299800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162000</td>\n",
       "      <td>0.307200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162500</td>\n",
       "      <td>0.303100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-1500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-1500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-3000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-3000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-4500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-4500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-6000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-6000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-7500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-7500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-10500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-10500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-10500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-12000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-12000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-12000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-13500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-13500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-13500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-15000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-15000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-15000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-27000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-27000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-27000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-28500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-28500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-28500/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-39000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-39000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-39000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-40500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-40500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-40500/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-49500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-49500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-49500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-49500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-49500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-51000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-51000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-51000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-61500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-61500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-61500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-61500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-61500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-63000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-63000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-63000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-63000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-63000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-72000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-72000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-72000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-72000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-72000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-73500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-73500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-73500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-73500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-73500/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-81000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-81000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-81000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-81000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-81000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-82500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-82500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-82500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-82500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-82500/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-90000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-90000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-90000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-91500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-91500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-91500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-91500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-91500/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-99000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-99000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-99000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-99000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-99000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-100500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-100500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-100500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-100500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-100500/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-108000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-108000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-108000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-108000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-108000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-109500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-109500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-109500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-109500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-109500/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-115500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-115500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-115500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-115500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-115500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-117000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-117000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-117000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-117000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-117000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-124500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-124500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-124500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-124500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-124500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-126000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-126000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-126000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-126000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-126000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-132000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-132000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-132000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-132000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-132000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-133500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-133500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-133500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-133500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-133500/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-139500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-139500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-139500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-139500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-139500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-141000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-141000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-141000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-141000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-141000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-147000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-147000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-147000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-147000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-147000/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-148500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-148500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-148500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-148500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-148500/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-154500\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-154500/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-154500/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-154500/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-154500/special_tokens_map.json\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-156000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-156000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-156000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-156000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-156000/special_tokens_map.json\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to Model_2/electra_checkpoint/checkpoint-162000\n",
      "Configuration saved in Model_2/electra_checkpoint/checkpoint-162000/config.json\n",
      "Model weights saved in Model_2/electra_checkpoint/checkpoint-162000/pytorch_model.bin\n",
      "tokenizer config file saved in Model_2/electra_checkpoint/checkpoint-162000/tokenizer_config.json\n",
      "Special tokens file saved in Model_2/electra_checkpoint/checkpoint-162000/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ab2ed7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.5986,\n",
       "  'learning_rate': 9.975000000000002e-06,\n",
       "  'epoch': 0.01,\n",
       "  'step': 500},\n",
       " {'loss': 0.4887,\n",
       "  'learning_rate': 9.950000000000001e-06,\n",
       "  'epoch': 0.03,\n",
       "  'step': 1000},\n",
       " {'loss': 0.4476, 'learning_rate': 9.925e-06, 'epoch': 0.04, 'step': 1500},\n",
       " {'loss': 0.4356, 'learning_rate': 9.9e-06, 'epoch': 0.05, 'step': 2000},\n",
       " {'loss': 0.4259,\n",
       "  'learning_rate': 9.875000000000001e-06,\n",
       "  'epoch': 0.06,\n",
       "  'step': 2500},\n",
       " {'loss': 0.4154, 'learning_rate': 9.85e-06, 'epoch': 0.07, 'step': 3000},\n",
       " {'loss': 0.4208,\n",
       "  'learning_rate': 9.825000000000002e-06,\n",
       "  'epoch': 0.09,\n",
       "  'step': 3500},\n",
       " {'loss': 0.4167,\n",
       "  'learning_rate': 9.800000000000001e-06,\n",
       "  'epoch': 0.1,\n",
       "  'step': 4000},\n",
       " {'loss': 0.4054, 'learning_rate': 9.775e-06, 'epoch': 0.11, 'step': 4500},\n",
       " {'loss': 0.4095, 'learning_rate': 9.75e-06, 'epoch': 0.12, 'step': 5000},\n",
       " {'loss': 0.405,\n",
       "  'learning_rate': 9.725000000000001e-06,\n",
       "  'epoch': 0.14,\n",
       "  'step': 5500},\n",
       " {'loss': 0.4057, 'learning_rate': 9.7e-06, 'epoch': 0.15, 'step': 6000},\n",
       " {'loss': 0.3955,\n",
       "  'learning_rate': 9.675000000000001e-06,\n",
       "  'epoch': 0.16,\n",
       "  'step': 6500},\n",
       " {'loss': 0.393, 'learning_rate': 9.65e-06, 'epoch': 0.17, 'step': 7000},\n",
       " {'loss': 0.4025, 'learning_rate': 9.625e-06, 'epoch': 0.19, 'step': 7500},\n",
       " {'loss': 0.3887,\n",
       "  'learning_rate': 9.600000000000001e-06,\n",
       "  'epoch': 0.2,\n",
       "  'step': 8000},\n",
       " {'loss': 0.3929, 'learning_rate': 9.575e-06, 'epoch': 0.21, 'step': 8500},\n",
       " {'loss': 0.3928, 'learning_rate': 9.55e-06, 'epoch': 0.23, 'step': 9000},\n",
       " {'loss': 0.3921,\n",
       "  'learning_rate': 9.525000000000001e-06,\n",
       "  'epoch': 0.24,\n",
       "  'step': 9500},\n",
       " {'loss': 0.3925, 'learning_rate': 9.5e-06, 'epoch': 0.25, 'step': 10000},\n",
       " {'loss': 0.3893,\n",
       "  'learning_rate': 9.475000000000002e-06,\n",
       "  'epoch': 0.26,\n",
       "  'step': 10500},\n",
       " {'loss': 0.3849,\n",
       "  'learning_rate': 9.450000000000001e-06,\n",
       "  'epoch': 0.28,\n",
       "  'step': 11000},\n",
       " {'loss': 0.3851, 'learning_rate': 9.425e-06, 'epoch': 0.29, 'step': 11500},\n",
       " {'loss': 0.3847, 'learning_rate': 9.4e-06, 'epoch': 0.3, 'step': 12000},\n",
       " {'loss': 0.3803,\n",
       "  'learning_rate': 9.375000000000001e-06,\n",
       "  'epoch': 0.31,\n",
       "  'step': 12500},\n",
       " {'loss': 0.3793,\n",
       "  'learning_rate': 9.350000000000002e-06,\n",
       "  'epoch': 0.33,\n",
       "  'step': 13000},\n",
       " {'loss': 0.3821,\n",
       "  'learning_rate': 9.325000000000001e-06,\n",
       "  'epoch': 0.34,\n",
       "  'step': 13500},\n",
       " {'loss': 0.3818, 'learning_rate': 9.3e-06, 'epoch': 0.35, 'step': 14000},\n",
       " {'loss': 0.3728, 'learning_rate': 9.275e-06, 'epoch': 0.36, 'step': 14500},\n",
       " {'loss': 0.3834,\n",
       "  'learning_rate': 9.250000000000001e-06,\n",
       "  'epoch': 0.38,\n",
       "  'step': 15000},\n",
       " {'loss': 0.3794, 'learning_rate': 9.225e-06, 'epoch': 0.39, 'step': 15500},\n",
       " {'loss': 0.3773,\n",
       "  'learning_rate': 9.200000000000002e-06,\n",
       "  'epoch': 0.4,\n",
       "  'step': 16000},\n",
       " {'loss': 0.3793,\n",
       "  'learning_rate': 9.175000000000001e-06,\n",
       "  'epoch': 0.41,\n",
       "  'step': 16500},\n",
       " {'loss': 0.3811, 'learning_rate': 9.15e-06, 'epoch': 0.42, 'step': 17000},\n",
       " {'loss': 0.3718, 'learning_rate': 9.125e-06, 'epoch': 0.44, 'step': 17500},\n",
       " {'loss': 0.3709,\n",
       "  'learning_rate': 9.100000000000001e-06,\n",
       "  'epoch': 0.45,\n",
       "  'step': 18000},\n",
       " {'loss': 0.3697, 'learning_rate': 9.075e-06, 'epoch': 0.46, 'step': 18500},\n",
       " {'loss': 0.3681,\n",
       "  'learning_rate': 9.050000000000001e-06,\n",
       "  'epoch': 0.47,\n",
       "  'step': 19000},\n",
       " {'loss': 0.3823, 'learning_rate': 9.025e-06, 'epoch': 0.49, 'step': 19500},\n",
       " {'loss': 0.3606, 'learning_rate': 9e-06, 'epoch': 0.5, 'step': 20000},\n",
       " {'loss': 0.3693, 'learning_rate': 8.975e-06, 'epoch': 0.51, 'step': 20500},\n",
       " {'loss': 0.3707, 'learning_rate': 8.95e-06, 'epoch': 0.53, 'step': 21000},\n",
       " {'loss': 0.3663, 'learning_rate': 8.925e-06, 'epoch': 0.54, 'step': 21500},\n",
       " {'loss': 0.3687,\n",
       "  'learning_rate': 8.900000000000001e-06,\n",
       "  'epoch': 0.55,\n",
       "  'step': 22000},\n",
       " {'loss': 0.3674, 'learning_rate': 8.875e-06, 'epoch': 0.56, 'step': 22500},\n",
       " {'loss': 0.3678, 'learning_rate': 8.85e-06, 'epoch': 0.57, 'step': 23000},\n",
       " {'loss': 0.3666,\n",
       "  'learning_rate': 8.825000000000001e-06,\n",
       "  'epoch': 0.59,\n",
       "  'step': 23500},\n",
       " {'loss': 0.3671, 'learning_rate': 8.8e-06, 'epoch': 0.6, 'step': 24000},\n",
       " {'loss': 0.3619, 'learning_rate': 8.775e-06, 'epoch': 0.61, 'step': 24500},\n",
       " {'loss': 0.3679,\n",
       "  'learning_rate': 8.750000000000001e-06,\n",
       "  'epoch': 0.62,\n",
       "  'step': 25000},\n",
       " {'loss': 0.3702,\n",
       "  'learning_rate': 8.725000000000002e-06,\n",
       "  'epoch': 0.64,\n",
       "  'step': 25500},\n",
       " {'loss': 0.3611,\n",
       "  'learning_rate': 8.700000000000001e-06,\n",
       "  'epoch': 0.65,\n",
       "  'step': 26000},\n",
       " {'loss': 0.3622, 'learning_rate': 8.675e-06, 'epoch': 0.66, 'step': 26500},\n",
       " {'loss': 0.3662, 'learning_rate': 8.65e-06, 'epoch': 0.68, 'step': 27000},\n",
       " {'loss': 0.3577,\n",
       "  'learning_rate': 8.625000000000001e-06,\n",
       "  'epoch': 0.69,\n",
       "  'step': 27500},\n",
       " {'loss': 0.3597, 'learning_rate': 8.6e-06, 'epoch': 0.7, 'step': 28000},\n",
       " {'loss': 0.357,\n",
       "  'learning_rate': 8.575000000000002e-06,\n",
       "  'epoch': 0.71,\n",
       "  'step': 28500},\n",
       " {'loss': 0.3602,\n",
       "  'learning_rate': 8.550000000000001e-06,\n",
       "  'epoch': 0.72,\n",
       "  'step': 29000},\n",
       " {'loss': 0.3617, 'learning_rate': 8.525e-06, 'epoch': 0.74, 'step': 29500},\n",
       " {'loss': 0.3574, 'learning_rate': 8.5e-06, 'epoch': 0.75, 'step': 30000},\n",
       " {'loss': 0.3583,\n",
       "  'learning_rate': 8.475000000000001e-06,\n",
       "  'epoch': 0.76,\n",
       "  'step': 30500},\n",
       " {'loss': 0.3595, 'learning_rate': 8.45e-06, 'epoch': 0.78, 'step': 31000},\n",
       " {'loss': 0.3608,\n",
       "  'learning_rate': 8.425000000000001e-06,\n",
       "  'epoch': 0.79,\n",
       "  'step': 31500},\n",
       " {'loss': 0.3627,\n",
       "  'learning_rate': 8.400000000000001e-06,\n",
       "  'epoch': 0.8,\n",
       "  'step': 32000},\n",
       " {'loss': 0.3567, 'learning_rate': 8.375e-06, 'epoch': 0.81, 'step': 32500},\n",
       " {'loss': 0.352, 'learning_rate': 8.35e-06, 'epoch': 0.82, 'step': 33000},\n",
       " {'loss': 0.3532, 'learning_rate': 8.325e-06, 'epoch': 0.84, 'step': 33500},\n",
       " {'loss': 0.3561, 'learning_rate': 8.3e-06, 'epoch': 0.85, 'step': 34000},\n",
       " {'loss': 0.3651,\n",
       "  'learning_rate': 8.275000000000001e-06,\n",
       "  'epoch': 0.86,\n",
       "  'step': 34500},\n",
       " {'loss': 0.3559, 'learning_rate': 8.25e-06, 'epoch': 0.88, 'step': 35000},\n",
       " {'loss': 0.3472, 'learning_rate': 8.225e-06, 'epoch': 0.89, 'step': 35500},\n",
       " {'loss': 0.3583, 'learning_rate': 8.2e-06, 'epoch': 0.9, 'step': 36000},\n",
       " {'loss': 0.3497, 'learning_rate': 8.175e-06, 'epoch': 0.91, 'step': 36500},\n",
       " {'loss': 0.3511, 'learning_rate': 8.15e-06, 'epoch': 0.93, 'step': 37000},\n",
       " {'loss': 0.3568,\n",
       "  'learning_rate': 8.125000000000001e-06,\n",
       "  'epoch': 0.94,\n",
       "  'step': 37500},\n",
       " {'loss': 0.3536, 'learning_rate': 8.1e-06, 'epoch': 0.95, 'step': 38000},\n",
       " {'loss': 0.3488,\n",
       "  'learning_rate': 8.075000000000001e-06,\n",
       "  'epoch': 0.96,\n",
       "  'step': 38500},\n",
       " {'loss': 0.3526,\n",
       "  'learning_rate': 8.050000000000001e-06,\n",
       "  'epoch': 0.97,\n",
       "  'step': 39000},\n",
       " {'loss': 0.3558, 'learning_rate': 8.025e-06, 'epoch': 0.99, 'step': 39500},\n",
       " {'loss': 0.3566,\n",
       "  'learning_rate': 8.000000000000001e-06,\n",
       "  'epoch': 1.0,\n",
       "  'step': 40000},\n",
       " {'loss': 0.3385, 'learning_rate': 7.975e-06, 'epoch': 1.01, 'step': 40500},\n",
       " {'loss': 0.345,\n",
       "  'learning_rate': 7.950000000000002e-06,\n",
       "  'epoch': 1.02,\n",
       "  'step': 41000},\n",
       " {'loss': 0.3376,\n",
       "  'learning_rate': 7.925000000000001e-06,\n",
       "  'epoch': 1.04,\n",
       "  'step': 41500},\n",
       " {'loss': 0.3373, 'learning_rate': 7.9e-06, 'epoch': 1.05, 'step': 42000},\n",
       " {'loss': 0.3512, 'learning_rate': 7.875e-06, 'epoch': 1.06, 'step': 42500},\n",
       " {'loss': 0.3402,\n",
       "  'learning_rate': 7.850000000000001e-06,\n",
       "  'epoch': 1.07,\n",
       "  'step': 43000},\n",
       " {'loss': 0.3505, 'learning_rate': 7.825e-06, 'epoch': 1.09, 'step': 43500},\n",
       " {'loss': 0.3461,\n",
       "  'learning_rate': 7.800000000000002e-06,\n",
       "  'epoch': 1.1,\n",
       "  'step': 44000},\n",
       " {'loss': 0.341,\n",
       "  'learning_rate': 7.775000000000001e-06,\n",
       "  'epoch': 1.11,\n",
       "  'step': 44500},\n",
       " {'loss': 0.3373, 'learning_rate': 7.75e-06, 'epoch': 1.12, 'step': 45000},\n",
       " {'loss': 0.3489, 'learning_rate': 7.725e-06, 'epoch': 1.14, 'step': 45500},\n",
       " {'loss': 0.3455, 'learning_rate': 7.7e-06, 'epoch': 1.15, 'step': 46000},\n",
       " {'loss': 0.3427, 'learning_rate': 7.675e-06, 'epoch': 1.16, 'step': 46500},\n",
       " {'loss': 0.3426,\n",
       "  'learning_rate': 7.650000000000001e-06,\n",
       "  'epoch': 1.18,\n",
       "  'step': 47000},\n",
       " {'loss': 0.3471, 'learning_rate': 7.625e-06, 'epoch': 1.19, 'step': 47500},\n",
       " {'loss': 0.3425,\n",
       "  'learning_rate': 7.600000000000001e-06,\n",
       "  'epoch': 1.2,\n",
       "  'step': 48000},\n",
       " {'loss': 0.3406, 'learning_rate': 7.575e-06, 'epoch': 1.21, 'step': 48500},\n",
       " {'loss': 0.3409,\n",
       "  'learning_rate': 7.5500000000000006e-06,\n",
       "  'epoch': 1.23,\n",
       "  'step': 49000},\n",
       " {'loss': 0.3444, 'learning_rate': 7.525e-06, 'epoch': 1.24, 'step': 49500},\n",
       " {'loss': 0.3446,\n",
       "  'learning_rate': 7.500000000000001e-06,\n",
       "  'epoch': 1.25,\n",
       "  'step': 50000},\n",
       " {'loss': 0.3419,\n",
       "  'learning_rate': 7.475000000000001e-06,\n",
       "  'epoch': 1.26,\n",
       "  'step': 50500},\n",
       " {'loss': 0.3386,\n",
       "  'learning_rate': 7.450000000000001e-06,\n",
       "  'epoch': 1.27,\n",
       "  'step': 51000},\n",
       " {'loss': 0.3452,\n",
       "  'learning_rate': 7.425000000000001e-06,\n",
       "  'epoch': 1.29,\n",
       "  'step': 51500},\n",
       " {'loss': 0.3368, 'learning_rate': 7.4e-06, 'epoch': 1.3, 'step': 52000},\n",
       " {'loss': 0.3407,\n",
       "  'learning_rate': 7.375000000000001e-06,\n",
       "  'epoch': 1.31,\n",
       "  'step': 52500},\n",
       " {'loss': 0.3341,\n",
       "  'learning_rate': 7.350000000000001e-06,\n",
       "  'epoch': 1.32,\n",
       "  'step': 53000},\n",
       " {'loss': 0.3326,\n",
       "  'learning_rate': 7.325000000000001e-06,\n",
       "  'epoch': 1.34,\n",
       "  'step': 53500},\n",
       " {'loss': 0.3383, 'learning_rate': 7.3e-06, 'epoch': 1.35, 'step': 54000},\n",
       " {'loss': 0.3464,\n",
       "  'learning_rate': 7.275000000000001e-06,\n",
       "  'epoch': 1.36,\n",
       "  'step': 54500},\n",
       " {'loss': 0.3408, 'learning_rate': 7.25e-06, 'epoch': 1.38, 'step': 55000},\n",
       " {'loss': 0.3419,\n",
       "  'learning_rate': 7.225000000000001e-06,\n",
       "  'epoch': 1.39,\n",
       "  'step': 55500},\n",
       " {'loss': 0.3276,\n",
       "  'learning_rate': 7.2000000000000005e-06,\n",
       "  'epoch': 1.4,\n",
       "  'step': 56000},\n",
       " {'loss': 0.3413,\n",
       "  'learning_rate': 7.175000000000001e-06,\n",
       "  'epoch': 1.41,\n",
       "  'step': 56500},\n",
       " {'loss': 0.3377, 'learning_rate': 7.15e-06, 'epoch': 1.43, 'step': 57000},\n",
       " {'loss': 0.3427, 'learning_rate': 7.125e-06, 'epoch': 1.44, 'step': 57500},\n",
       " {'loss': 0.3335,\n",
       "  'learning_rate': 7.100000000000001e-06,\n",
       "  'epoch': 1.45,\n",
       "  'step': 58000},\n",
       " {'loss': 0.34,\n",
       "  'learning_rate': 7.075000000000001e-06,\n",
       "  'epoch': 1.46,\n",
       "  'step': 58500},\n",
       " {'loss': 0.3444, 'learning_rate': 7.05e-06, 'epoch': 1.48, 'step': 59000},\n",
       " {'loss': 0.3383,\n",
       "  'learning_rate': 7.0250000000000005e-06,\n",
       "  'epoch': 1.49,\n",
       "  'step': 59500},\n",
       " {'loss': 0.34, 'learning_rate': 7e-06, 'epoch': 1.5, 'step': 60000},\n",
       " {'loss': 0.335,\n",
       "  'learning_rate': 6.975000000000001e-06,\n",
       "  'epoch': 1.51,\n",
       "  'step': 60500},\n",
       " {'loss': 0.3347, 'learning_rate': 6.95e-06, 'epoch': 1.52, 'step': 61000},\n",
       " {'loss': 0.335,\n",
       "  'learning_rate': 6.925000000000001e-06,\n",
       "  'epoch': 1.54,\n",
       "  'step': 61500},\n",
       " {'loss': 0.3431, 'learning_rate': 6.9e-06, 'epoch': 1.55, 'step': 62000},\n",
       " {'loss': 0.3327, 'learning_rate': 6.875e-06, 'epoch': 1.56, 'step': 62500},\n",
       " {'loss': 0.3319,\n",
       "  'learning_rate': 6.850000000000001e-06,\n",
       "  'epoch': 1.57,\n",
       "  'step': 63000},\n",
       " {'loss': 0.3372,\n",
       "  'learning_rate': 6.825000000000001e-06,\n",
       "  'epoch': 1.59,\n",
       "  'step': 63500},\n",
       " {'loss': 0.343,\n",
       "  'learning_rate': 6.800000000000001e-06,\n",
       "  'epoch': 1.6,\n",
       "  'step': 64000},\n",
       " {'loss': 0.3329, 'learning_rate': 6.775e-06, 'epoch': 1.61, 'step': 64500},\n",
       " {'loss': 0.3343,\n",
       "  'learning_rate': 6.750000000000001e-06,\n",
       "  'epoch': 1.62,\n",
       "  'step': 65000},\n",
       " {'loss': 0.3374,\n",
       "  'learning_rate': 6.725000000000001e-06,\n",
       "  'epoch': 1.64,\n",
       "  'step': 65500},\n",
       " {'loss': 0.3354,\n",
       "  'learning_rate': 6.700000000000001e-06,\n",
       "  'epoch': 1.65,\n",
       "  'step': 66000},\n",
       " {'loss': 0.3414,\n",
       "  'learning_rate': 6.6750000000000005e-06,\n",
       "  'epoch': 1.66,\n",
       "  'step': 66500},\n",
       " {'loss': 0.3298,\n",
       "  'learning_rate': 6.650000000000001e-06,\n",
       "  'epoch': 1.68,\n",
       "  'step': 67000},\n",
       " {'loss': 0.3426, 'learning_rate': 6.625e-06, 'epoch': 1.69, 'step': 67500},\n",
       " {'loss': 0.3471,\n",
       "  'learning_rate': 6.600000000000001e-06,\n",
       "  'epoch': 1.7,\n",
       "  'step': 68000},\n",
       " {'loss': 0.3353,\n",
       "  'learning_rate': 6.5750000000000006e-06,\n",
       "  'epoch': 1.71,\n",
       "  'step': 68500},\n",
       " {'loss': 0.3334,\n",
       "  'learning_rate': 6.550000000000001e-06,\n",
       "  'epoch': 1.73,\n",
       "  'step': 69000},\n",
       " {'loss': 0.3301, 'learning_rate': 6.525e-06, 'epoch': 1.74, 'step': 69500},\n",
       " {'loss': 0.3408,\n",
       "  'learning_rate': 6.5000000000000004e-06,\n",
       "  'epoch': 1.75,\n",
       "  'step': 70000},\n",
       " {'loss': 0.3338, 'learning_rate': 6.475e-06, 'epoch': 1.76, 'step': 70500},\n",
       " {'loss': 0.3374,\n",
       "  'learning_rate': 6.450000000000001e-06,\n",
       "  'epoch': 1.77,\n",
       "  'step': 71000},\n",
       " {'loss': 0.3279, 'learning_rate': 6.425e-06, 'epoch': 1.79, 'step': 71500},\n",
       " {'loss': 0.3327,\n",
       "  'learning_rate': 6.4000000000000006e-06,\n",
       "  'epoch': 1.8,\n",
       "  'step': 72000},\n",
       " {'loss': 0.3351, 'learning_rate': 6.375e-06, 'epoch': 1.81, 'step': 72500},\n",
       " {'loss': 0.333, 'learning_rate': 6.35e-06, 'epoch': 1.82, 'step': 73000},\n",
       " {'loss': 0.3349,\n",
       "  'learning_rate': 6.3250000000000004e-06,\n",
       "  'epoch': 1.84,\n",
       "  'step': 73500},\n",
       " {'loss': 0.3361,\n",
       "  'learning_rate': 6.300000000000001e-06,\n",
       "  'epoch': 1.85,\n",
       "  'step': 74000},\n",
       " {'loss': 0.3298, 'learning_rate': 6.275e-06, 'epoch': 1.86, 'step': 74500},\n",
       " {'loss': 0.329, 'learning_rate': 6.25e-06, 'epoch': 1.88, 'step': 75000},\n",
       " {'loss': 0.3323,\n",
       "  'learning_rate': 6.225000000000001e-06,\n",
       "  'epoch': 1.89,\n",
       "  'step': 75500},\n",
       " {'loss': 0.3307,\n",
       "  'learning_rate': 6.200000000000001e-06,\n",
       "  'epoch': 1.9,\n",
       "  'step': 76000},\n",
       " {'loss': 0.3318,\n",
       "  'learning_rate': 6.175000000000001e-06,\n",
       "  'epoch': 1.91,\n",
       "  'step': 76500},\n",
       " {'loss': 0.3407, 'learning_rate': 6.15e-06, 'epoch': 1.93, 'step': 77000},\n",
       " {'loss': 0.3308,\n",
       "  'learning_rate': 6.125000000000001e-06,\n",
       "  'epoch': 1.94,\n",
       "  'step': 77500},\n",
       " {'loss': 0.3359, 'learning_rate': 6.1e-06, 'epoch': 1.95, 'step': 78000},\n",
       " {'loss': 0.3271,\n",
       "  'learning_rate': 6.075000000000001e-06,\n",
       "  'epoch': 1.96,\n",
       "  'step': 78500},\n",
       " {'loss': 0.3359,\n",
       "  'learning_rate': 6.0500000000000005e-06,\n",
       "  'epoch': 1.98,\n",
       "  'step': 79000},\n",
       " {'loss': 0.3336,\n",
       "  'learning_rate': 6.025000000000001e-06,\n",
       "  'epoch': 1.99,\n",
       "  'step': 79500},\n",
       " {'loss': 0.336, 'learning_rate': 6e-06, 'epoch': 2.0, 'step': 80000},\n",
       " {'loss': 0.3242, 'learning_rate': 5.975e-06, 'epoch': 2.01, 'step': 80500},\n",
       " {'loss': 0.3253,\n",
       "  'learning_rate': 5.950000000000001e-06,\n",
       "  'epoch': 2.02,\n",
       "  'step': 81000},\n",
       " {'loss': 0.3275,\n",
       "  'learning_rate': 5.925000000000001e-06,\n",
       "  'epoch': 2.04,\n",
       "  'step': 81500},\n",
       " {'loss': 0.3213, 'learning_rate': 5.9e-06, 'epoch': 2.05, 'step': 82000},\n",
       " {'loss': 0.3253,\n",
       "  'learning_rate': 5.8750000000000005e-06,\n",
       "  'epoch': 2.06,\n",
       "  'step': 82500},\n",
       " {'loss': 0.3179, 'learning_rate': 5.85e-06, 'epoch': 2.08, 'step': 83000},\n",
       " {'loss': 0.325,\n",
       "  'learning_rate': 5.825000000000001e-06,\n",
       "  'epoch': 2.09,\n",
       "  'step': 83500},\n",
       " {'loss': 0.3225, 'learning_rate': 5.8e-06, 'epoch': 2.1, 'step': 84000},\n",
       " {'loss': 0.3191,\n",
       "  'learning_rate': 5.775000000000001e-06,\n",
       "  'epoch': 2.11,\n",
       "  'step': 84500},\n",
       " {'loss': 0.3245, 'learning_rate': 5.75e-06, 'epoch': 2.12, 'step': 85000},\n",
       " {'loss': 0.3141, 'learning_rate': 5.725e-06, 'epoch': 2.14, 'step': 85500},\n",
       " {'loss': 0.3241, 'learning_rate': 5.7e-06, 'epoch': 2.15, 'step': 86000},\n",
       " {'loss': 0.3239,\n",
       "  'learning_rate': 5.675000000000001e-06,\n",
       "  'epoch': 2.16,\n",
       "  'step': 86500},\n",
       " {'loss': 0.3199, 'learning_rate': 5.65e-06, 'epoch': 2.17, 'step': 87000},\n",
       " {'loss': 0.3294, 'learning_rate': 5.625e-06, 'epoch': 2.19, 'step': 87500},\n",
       " {'loss': 0.3191,\n",
       "  'learning_rate': 5.600000000000001e-06,\n",
       "  'epoch': 2.2,\n",
       "  'step': 88000},\n",
       " {'loss': 0.3169,\n",
       "  'learning_rate': 5.575000000000001e-06,\n",
       "  'epoch': 2.21,\n",
       "  'step': 88500},\n",
       " {'loss': 0.3284,\n",
       "  'learning_rate': 5.550000000000001e-06,\n",
       "  'epoch': 2.23,\n",
       "  'step': 89000},\n",
       " {'loss': 0.3228,\n",
       "  'learning_rate': 5.5250000000000005e-06,\n",
       "  'epoch': 2.24,\n",
       "  'step': 89500},\n",
       " {'loss': 0.3186,\n",
       "  'learning_rate': 5.500000000000001e-06,\n",
       "  'epoch': 2.25,\n",
       "  'step': 90000},\n",
       " {'loss': 0.3245, 'learning_rate': 5.475e-06, 'epoch': 2.26, 'step': 90500},\n",
       " {'loss': 0.3207,\n",
       "  'learning_rate': 5.450000000000001e-06,\n",
       "  'epoch': 2.27,\n",
       "  'step': 91000},\n",
       " {'loss': 0.3226,\n",
       "  'learning_rate': 5.4250000000000006e-06,\n",
       "  'epoch': 2.29,\n",
       "  'step': 91500},\n",
       " {'loss': 0.3204,\n",
       "  'learning_rate': 5.400000000000001e-06,\n",
       "  'epoch': 2.3,\n",
       "  'step': 92000},\n",
       " {'loss': 0.3225, 'learning_rate': 5.375e-06, 'epoch': 2.31, 'step': 92500},\n",
       " {'loss': 0.3225,\n",
       "  'learning_rate': 5.3500000000000004e-06,\n",
       "  'epoch': 2.33,\n",
       "  'step': 93000},\n",
       " {'loss': 0.3153, 'learning_rate': 5.325e-06, 'epoch': 2.34, 'step': 93500},\n",
       " {'loss': 0.3217,\n",
       "  'learning_rate': 5.300000000000001e-06,\n",
       "  'epoch': 2.35,\n",
       "  'step': 94000},\n",
       " {'loss': 0.322, 'learning_rate': 5.275e-06, 'epoch': 2.36, 'step': 94500},\n",
       " {'loss': 0.3231,\n",
       "  'learning_rate': 5.2500000000000006e-06,\n",
       "  'epoch': 2.38,\n",
       "  'step': 95000},\n",
       " {'loss': 0.3193, 'learning_rate': 5.225e-06, 'epoch': 2.39, 'step': 95500},\n",
       " {'loss': 0.3301, 'learning_rate': 5.2e-06, 'epoch': 2.4, 'step': 96000},\n",
       " {'loss': 0.3187,\n",
       "  'learning_rate': 5.1750000000000004e-06,\n",
       "  'epoch': 2.41,\n",
       "  'step': 96500},\n",
       " {'loss': 0.3284,\n",
       "  'learning_rate': 5.150000000000001e-06,\n",
       "  'epoch': 2.42,\n",
       "  'step': 97000},\n",
       " {'loss': 0.3221, 'learning_rate': 5.125e-06, 'epoch': 2.44, 'step': 97500},\n",
       " {'loss': 0.3248, 'learning_rate': 5.1e-06, 'epoch': 2.45, 'step': 98000},\n",
       " {'loss': 0.3226, 'learning_rate': 5.075e-06, 'epoch': 2.46, 'step': 98500},\n",
       " {'loss': 0.316,\n",
       "  'learning_rate': 5.050000000000001e-06,\n",
       "  'epoch': 2.48,\n",
       "  'step': 99000},\n",
       " {'loss': 0.3202, 'learning_rate': 5.025e-06, 'epoch': 2.49, 'step': 99500},\n",
       " {'loss': 0.3264, 'learning_rate': 5e-06, 'epoch': 2.5, 'step': 100000},\n",
       " {'loss': 0.3199,\n",
       "  'learning_rate': 4.975000000000001e-06,\n",
       "  'epoch': 2.51,\n",
       "  'step': 100500},\n",
       " {'loss': 0.3129, 'learning_rate': 4.95e-06, 'epoch': 2.52, 'step': 101000},\n",
       " {'loss': 0.3113, 'learning_rate': 4.925e-06, 'epoch': 2.54, 'step': 101500},\n",
       " {'loss': 0.3178,\n",
       "  'learning_rate': 4.9000000000000005e-06,\n",
       "  'epoch': 2.55,\n",
       "  'step': 102000},\n",
       " {'loss': 0.3195, 'learning_rate': 4.875e-06, 'epoch': 2.56, 'step': 102500},\n",
       " {'loss': 0.3251, 'learning_rate': 4.85e-06, 'epoch': 2.58, 'step': 103000},\n",
       " {'loss': 0.328, 'learning_rate': 4.825e-06, 'epoch': 2.59, 'step': 103500},\n",
       " {'loss': 0.3178,\n",
       "  'learning_rate': 4.800000000000001e-06,\n",
       "  'epoch': 2.6,\n",
       "  'step': 104000},\n",
       " {'loss': 0.3301, 'learning_rate': 4.775e-06, 'epoch': 2.61, 'step': 104500},\n",
       " {'loss': 0.3219, 'learning_rate': 4.75e-06, 'epoch': 2.62, 'step': 105000},\n",
       " {'loss': 0.3228,\n",
       "  'learning_rate': 4.7250000000000005e-06,\n",
       "  'epoch': 2.64,\n",
       "  'step': 105500},\n",
       " {'loss': 0.3255, 'learning_rate': 4.7e-06, 'epoch': 2.65, 'step': 106000},\n",
       " {'loss': 0.3259,\n",
       "  'learning_rate': 4.675000000000001e-06,\n",
       "  'epoch': 2.66,\n",
       "  'step': 106500},\n",
       " {'loss': 0.3201, 'learning_rate': 4.65e-06, 'epoch': 2.67, 'step': 107000},\n",
       " {'loss': 0.315,\n",
       "  'learning_rate': 4.625000000000001e-06,\n",
       "  'epoch': 2.69,\n",
       "  'step': 107500},\n",
       " {'loss': 0.3184,\n",
       "  'learning_rate': 4.600000000000001e-06,\n",
       "  'epoch': 2.7,\n",
       "  'step': 108000},\n",
       " {'loss': 0.3211, 'learning_rate': 4.575e-06, 'epoch': 2.71, 'step': 108500},\n",
       " {'loss': 0.3178,\n",
       "  'learning_rate': 4.5500000000000005e-06,\n",
       "  'epoch': 2.73,\n",
       "  'step': 109000},\n",
       " {'loss': 0.3225,\n",
       "  'learning_rate': 4.525000000000001e-06,\n",
       "  'epoch': 2.74,\n",
       "  'step': 109500},\n",
       " {'loss': 0.3156, 'learning_rate': 4.5e-06, 'epoch': 2.75, 'step': 110000},\n",
       " {'loss': 0.3274, 'learning_rate': 4.475e-06, 'epoch': 2.76, 'step': 110500},\n",
       " {'loss': 0.3248,\n",
       "  'learning_rate': 4.450000000000001e-06,\n",
       "  'epoch': 2.77,\n",
       "  'step': 111000},\n",
       " {'loss': 0.3226, 'learning_rate': 4.425e-06, 'epoch': 2.79, 'step': 111500},\n",
       " {'loss': 0.3225, 'learning_rate': 4.4e-06, 'epoch': 2.8, 'step': 112000},\n",
       " {'loss': 0.3163,\n",
       "  'learning_rate': 4.3750000000000005e-06,\n",
       "  'epoch': 2.81,\n",
       "  'step': 112500},\n",
       " {'loss': 0.3242,\n",
       "  'learning_rate': 4.350000000000001e-06,\n",
       "  'epoch': 2.83,\n",
       "  'step': 113000},\n",
       " {'loss': 0.3228, 'learning_rate': 4.325e-06, 'epoch': 2.84, 'step': 113500},\n",
       " {'loss': 0.3193, 'learning_rate': 4.3e-06, 'epoch': 2.85, 'step': 114000},\n",
       " {'loss': 0.3152,\n",
       "  'learning_rate': 4.2750000000000006e-06,\n",
       "  'epoch': 2.86,\n",
       "  'step': 114500},\n",
       " {'loss': 0.3252, 'learning_rate': 4.25e-06, 'epoch': 2.88, 'step': 115000},\n",
       " {'loss': 0.3186, 'learning_rate': 4.225e-06, 'epoch': 2.89, 'step': 115500},\n",
       " {'loss': 0.3226,\n",
       "  'learning_rate': 4.2000000000000004e-06,\n",
       "  'epoch': 2.9,\n",
       "  'step': 116000},\n",
       " {'loss': 0.3243, 'learning_rate': 4.175e-06, 'epoch': 2.91, 'step': 116500},\n",
       " {'loss': 0.3138, 'learning_rate': 4.15e-06, 'epoch': 2.92, 'step': 117000},\n",
       " {'loss': 0.315, 'learning_rate': 4.125e-06, 'epoch': 2.94, 'step': 117500},\n",
       " {'loss': 0.3235, 'learning_rate': 4.1e-06, 'epoch': 2.95, 'step': 118000},\n",
       " {'loss': 0.3156, 'learning_rate': 4.075e-06, 'epoch': 2.96, 'step': 118500},\n",
       " {'loss': 0.3193, 'learning_rate': 4.05e-06, 'epoch': 2.98, 'step': 119000},\n",
       " {'loss': 0.3184,\n",
       "  'learning_rate': 4.0250000000000004e-06,\n",
       "  'epoch': 2.99,\n",
       "  'step': 119500},\n",
       " {'loss': 0.314,\n",
       "  'learning_rate': 4.000000000000001e-06,\n",
       "  'epoch': 3.0,\n",
       "  'step': 120000},\n",
       " {'loss': 0.3128,\n",
       "  'learning_rate': 3.975000000000001e-06,\n",
       "  'epoch': 3.01,\n",
       "  'step': 120500},\n",
       " {'loss': 0.3085, 'learning_rate': 3.95e-06, 'epoch': 3.02, 'step': 121000},\n",
       " {'loss': 0.3055,\n",
       "  'learning_rate': 3.9250000000000005e-06,\n",
       "  'epoch': 3.04,\n",
       "  'step': 121500},\n",
       " {'loss': 0.3046,\n",
       "  'learning_rate': 3.900000000000001e-06,\n",
       "  'epoch': 3.05,\n",
       "  'step': 122000},\n",
       " {'loss': 0.3151, 'learning_rate': 3.875e-06, 'epoch': 3.06, 'step': 122500},\n",
       " {'loss': 0.3116, 'learning_rate': 3.85e-06, 'epoch': 3.08, 'step': 123000},\n",
       " {'loss': 0.3161,\n",
       "  'learning_rate': 3.825000000000001e-06,\n",
       "  'epoch': 3.09,\n",
       "  'step': 123500},\n",
       " {'loss': 0.3052,\n",
       "  'learning_rate': 3.8000000000000005e-06,\n",
       "  'epoch': 3.1,\n",
       "  'step': 124000},\n",
       " {'loss': 0.3098,\n",
       "  'learning_rate': 3.7750000000000003e-06,\n",
       "  'epoch': 3.11,\n",
       "  'step': 124500},\n",
       " {'loss': 0.3093,\n",
       "  'learning_rate': 3.7500000000000005e-06,\n",
       "  'epoch': 3.12,\n",
       "  'step': 125000},\n",
       " {'loss': 0.306,\n",
       "  'learning_rate': 3.7250000000000003e-06,\n",
       "  'epoch': 3.14,\n",
       "  'step': 125500},\n",
       " {'loss': 0.3054, 'learning_rate': 3.7e-06, 'epoch': 3.15, 'step': 126000},\n",
       " {'loss': 0.3108,\n",
       "  'learning_rate': 3.6750000000000004e-06,\n",
       "  'epoch': 3.16,\n",
       "  'step': 126500},\n",
       " {'loss': 0.3149, 'learning_rate': 3.65e-06, 'epoch': 3.17, 'step': 127000},\n",
       " {'loss': 0.3072, 'learning_rate': 3.625e-06, 'epoch': 3.19, 'step': 127500},\n",
       " {'loss': 0.31,\n",
       "  'learning_rate': 3.6000000000000003e-06,\n",
       "  'epoch': 3.2,\n",
       "  'step': 128000},\n",
       " {'loss': 0.3071, 'learning_rate': 3.575e-06, 'epoch': 3.21, 'step': 128500},\n",
       " {'loss': 0.3086,\n",
       "  'learning_rate': 3.5500000000000003e-06,\n",
       "  'epoch': 3.23,\n",
       "  'step': 129000},\n",
       " {'loss': 0.3038, 'learning_rate': 3.525e-06, 'epoch': 3.24, 'step': 129500},\n",
       " {'loss': 0.3105, 'learning_rate': 3.5e-06, 'epoch': 3.25, 'step': 130000},\n",
       " {'loss': 0.3071, 'learning_rate': 3.475e-06, 'epoch': 3.26, 'step': 130500},\n",
       " {'loss': 0.3067, 'learning_rate': 3.45e-06, 'epoch': 3.27, 'step': 131000},\n",
       " {'loss': 0.3147,\n",
       "  'learning_rate': 3.4250000000000007e-06,\n",
       "  'epoch': 3.29,\n",
       "  'step': 131500},\n",
       " {'loss': 0.3034,\n",
       "  'learning_rate': 3.4000000000000005e-06,\n",
       "  'epoch': 3.3,\n",
       "  'step': 132000},\n",
       " {'loss': 0.3106,\n",
       "  'learning_rate': 3.3750000000000003e-06,\n",
       "  'epoch': 3.31,\n",
       "  'step': 132500},\n",
       " {'loss': 0.3142,\n",
       "  'learning_rate': 3.3500000000000005e-06,\n",
       "  'epoch': 3.33,\n",
       "  'step': 133000},\n",
       " {'loss': 0.3138,\n",
       "  'learning_rate': 3.3250000000000004e-06,\n",
       "  'epoch': 3.34,\n",
       "  'step': 133500},\n",
       " {'loss': 0.3053,\n",
       "  'learning_rate': 3.3000000000000006e-06,\n",
       "  'epoch': 3.35,\n",
       "  'step': 134000},\n",
       " {'loss': 0.3126,\n",
       "  'learning_rate': 3.2750000000000004e-06,\n",
       "  'epoch': 3.36,\n",
       "  'step': 134500},\n",
       " {'loss': 0.3145,\n",
       "  'learning_rate': 3.2500000000000002e-06,\n",
       "  'epoch': 3.38,\n",
       "  'step': 135000},\n",
       " {'loss': 0.3109,\n",
       "  'learning_rate': 3.2250000000000005e-06,\n",
       "  'epoch': 3.39,\n",
       "  'step': 135500},\n",
       " {'loss': 0.3099,\n",
       "  'learning_rate': 3.2000000000000003e-06,\n",
       "  'epoch': 3.4,\n",
       "  'step': 136000},\n",
       " {'loss': 0.3134, 'learning_rate': 3.175e-06, 'epoch': 3.41, 'step': 136500},\n",
       " {'loss': 0.3022,\n",
       "  'learning_rate': 3.1500000000000003e-06,\n",
       "  'epoch': 3.42,\n",
       "  'step': 137000},\n",
       " {'loss': 0.314, 'learning_rate': 3.125e-06, 'epoch': 3.44, 'step': 137500},\n",
       " {'loss': 0.3161,\n",
       "  'learning_rate': 3.1000000000000004e-06,\n",
       "  'epoch': 3.45,\n",
       "  'step': 138000},\n",
       " {'loss': 0.3118, 'learning_rate': 3.075e-06, 'epoch': 3.46, 'step': 138500},\n",
       " {'loss': 0.307, 'learning_rate': 3.05e-06, 'epoch': 3.48, 'step': 139000},\n",
       " {'loss': 0.3105,\n",
       "  'learning_rate': 3.0250000000000003e-06,\n",
       "  'epoch': 3.49,\n",
       "  'step': 139500},\n",
       " {'loss': 0.3094, 'learning_rate': 3e-06, 'epoch': 3.5, 'step': 140000},\n",
       " {'loss': 0.3169,\n",
       "  'learning_rate': 2.9750000000000003e-06,\n",
       "  'epoch': 3.51,\n",
       "  'step': 140500},\n",
       " {'loss': 0.3112, 'learning_rate': 2.95e-06, 'epoch': 3.52, 'step': 141000},\n",
       " {'loss': 0.3116, 'learning_rate': 2.925e-06, 'epoch': 3.54, 'step': 141500},\n",
       " {'loss': 0.314, 'learning_rate': 2.9e-06, 'epoch': 3.55, 'step': 142000},\n",
       " {'loss': 0.3, 'learning_rate': 2.875e-06, 'epoch': 3.56, 'step': 142500},\n",
       " {'loss': 0.3131, 'learning_rate': 2.85e-06, 'epoch': 3.58, 'step': 143000},\n",
       " {'loss': 0.306, 'learning_rate': 2.825e-06, 'epoch': 3.59, 'step': 143500},\n",
       " {'loss': 0.3169,\n",
       "  'learning_rate': 2.8000000000000003e-06,\n",
       "  'epoch': 3.6,\n",
       "  'step': 144000},\n",
       " {'loss': 0.3178,\n",
       "  'learning_rate': 2.7750000000000005e-06,\n",
       "  'epoch': 3.61,\n",
       "  'step': 144500},\n",
       " {'loss': 0.3094,\n",
       "  'learning_rate': 2.7500000000000004e-06,\n",
       "  'epoch': 3.62,\n",
       "  'step': 145000},\n",
       " {'loss': 0.3107,\n",
       "  'learning_rate': 2.7250000000000006e-06,\n",
       "  'epoch': 3.64,\n",
       "  'step': 145500},\n",
       " {'loss': 0.308,\n",
       "  'learning_rate': 2.7000000000000004e-06,\n",
       "  'epoch': 3.65,\n",
       "  'step': 146000},\n",
       " {'loss': 0.3103,\n",
       "  'learning_rate': 2.6750000000000002e-06,\n",
       "  'epoch': 3.66,\n",
       "  'step': 146500},\n",
       " {'loss': 0.3128,\n",
       "  'learning_rate': 2.6500000000000005e-06,\n",
       "  'epoch': 3.67,\n",
       "  'step': 147000},\n",
       " {'loss': 0.3045,\n",
       "  'learning_rate': 2.6250000000000003e-06,\n",
       "  'epoch': 3.69,\n",
       "  'step': 147500},\n",
       " {'loss': 0.309, 'learning_rate': 2.6e-06, 'epoch': 3.7, 'step': 148000},\n",
       " {'loss': 0.3156,\n",
       "  'learning_rate': 2.5750000000000003e-06,\n",
       "  'epoch': 3.71,\n",
       "  'step': 148500},\n",
       " {'loss': 0.3066, 'learning_rate': 2.55e-06, 'epoch': 3.73, 'step': 149000},\n",
       " {'loss': 0.3172,\n",
       "  'learning_rate': 2.5250000000000004e-06,\n",
       "  'epoch': 3.74,\n",
       "  'step': 149500},\n",
       " {'loss': 0.3123, 'learning_rate': 2.5e-06, 'epoch': 3.75, 'step': 150000},\n",
       " {'loss': 0.3069, 'learning_rate': 2.475e-06, 'epoch': 3.76, 'step': 150500},\n",
       " {'loss': 0.3141,\n",
       "  'learning_rate': 2.4500000000000003e-06,\n",
       "  'epoch': 3.77,\n",
       "  'step': 151000},\n",
       " {'loss': 0.315, 'learning_rate': 2.425e-06, 'epoch': 3.79, 'step': 151500},\n",
       " {'loss': 0.3102,\n",
       "  'learning_rate': 2.4000000000000003e-06,\n",
       "  'epoch': 3.8,\n",
       "  'step': 152000},\n",
       " {'loss': 0.311, 'learning_rate': 2.375e-06, 'epoch': 3.81, 'step': 152500},\n",
       " {'loss': 0.3077, 'learning_rate': 2.35e-06, 'epoch': 3.83, 'step': 153000},\n",
       " {'loss': 0.318, 'learning_rate': 2.325e-06, 'epoch': 3.84, 'step': 153500},\n",
       " {'loss': 0.3086,\n",
       "  'learning_rate': 2.3000000000000004e-06,\n",
       "  'epoch': 3.85,\n",
       "  'step': 154000},\n",
       " {'loss': 0.3054,\n",
       "  'learning_rate': 2.2750000000000002e-06,\n",
       "  'epoch': 3.86,\n",
       "  'step': 154500},\n",
       " {'loss': 0.3088, 'learning_rate': 2.25e-06, 'epoch': 3.88, 'step': 155000},\n",
       " {'loss': 0.3104,\n",
       "  'learning_rate': 2.2250000000000003e-06,\n",
       "  'epoch': 3.89,\n",
       "  'step': 155500},\n",
       " {'loss': 0.31, 'learning_rate': 2.2e-06, 'epoch': 3.9, 'step': 156000},\n",
       " {'loss': 0.31,\n",
       "  'learning_rate': 2.1750000000000004e-06,\n",
       "  'epoch': 3.91,\n",
       "  'step': 156500},\n",
       " {'loss': 0.3113, 'learning_rate': 2.15e-06, 'epoch': 3.92, 'step': 157000},\n",
       " {'loss': 0.3164, 'learning_rate': 2.125e-06, 'epoch': 3.94, 'step': 157500},\n",
       " {'loss': 0.3075,\n",
       "  'learning_rate': 2.1000000000000002e-06,\n",
       "  'epoch': 3.95,\n",
       "  'step': 158000},\n",
       " {'loss': 0.3085, 'learning_rate': 2.075e-06, 'epoch': 3.96, 'step': 158500},\n",
       " {'loss': 0.3126, 'learning_rate': 2.05e-06, 'epoch': 3.98, 'step': 159000},\n",
       " {'loss': 0.3043, 'learning_rate': 2.025e-06, 'epoch': 3.99, 'step': 159500},\n",
       " {'loss': 0.3154,\n",
       "  'learning_rate': 2.0000000000000003e-06,\n",
       "  'epoch': 4.0,\n",
       "  'step': 160000},\n",
       " {'loss': 0.3048, 'learning_rate': 1.975e-06, 'epoch': 4.01, 'step': 160500},\n",
       " {'loss': 0.3004,\n",
       "  'learning_rate': 1.9500000000000004e-06,\n",
       "  'epoch': 4.03,\n",
       "  'step': 161000},\n",
       " {'loss': 0.2998, 'learning_rate': 1.925e-06, 'epoch': 4.04, 'step': 161500},\n",
       " {'loss': 0.3072,\n",
       "  'learning_rate': 1.9000000000000002e-06,\n",
       "  'epoch': 4.05,\n",
       "  'step': 162000},\n",
       " {'loss': 0.3031,\n",
       "  'learning_rate': 1.8750000000000003e-06,\n",
       "  'epoch': 4.06,\n",
       "  'step': 162500},\n",
       " {'loss': 0.3022, 'learning_rate': 1.85e-06, 'epoch': 4.08, 'step': 163000},\n",
       " {'loss': 0.3059, 'learning_rate': 1.825e-06, 'epoch': 4.09, 'step': 163500},\n",
       " {'loss': 0.3089,\n",
       "  'learning_rate': 1.8000000000000001e-06,\n",
       "  'epoch': 4.1,\n",
       "  'step': 164000},\n",
       " {'loss': 0.3058,\n",
       "  'learning_rate': 1.7750000000000002e-06,\n",
       "  'epoch': 4.11,\n",
       "  'step': 164500},\n",
       " {'loss': 0.3029, 'learning_rate': 1.75e-06, 'epoch': 4.12, 'step': 165000},\n",
       " {'loss': 0.3126, 'learning_rate': 1.725e-06, 'epoch': 4.14, 'step': 165500},\n",
       " {'loss': 0.2998,\n",
       "  'learning_rate': 1.7000000000000002e-06,\n",
       "  'epoch': 4.15,\n",
       "  'step': 166000},\n",
       " {'loss': 0.3048,\n",
       "  'learning_rate': 1.6750000000000003e-06,\n",
       "  'epoch': 4.16,\n",
       "  'step': 166500},\n",
       " {'loss': 0.2901,\n",
       "  'learning_rate': 1.6500000000000003e-06,\n",
       "  'epoch': 4.17,\n",
       "  'step': 167000},\n",
       " {'loss': 0.3014,\n",
       "  'learning_rate': 1.6250000000000001e-06,\n",
       "  'epoch': 4.19,\n",
       "  'step': 167500},\n",
       " {'loss': 0.3103,\n",
       "  'learning_rate': 1.6000000000000001e-06,\n",
       "  'epoch': 4.2,\n",
       "  'step': 168000},\n",
       " {'loss': 0.299,\n",
       "  'learning_rate': 1.5750000000000002e-06,\n",
       "  'epoch': 4.21,\n",
       "  'step': 168500},\n",
       " {'loss': 0.2981,\n",
       "  'learning_rate': 1.5500000000000002e-06,\n",
       "  'epoch': 4.22,\n",
       "  'step': 169000},\n",
       " {'loss': 0.3081, 'learning_rate': 1.525e-06, 'epoch': 4.24, 'step': 169500},\n",
       " {'loss': 0.306, 'learning_rate': 1.5e-06, 'epoch': 4.25, 'step': 170000},\n",
       " {'loss': 0.2999, 'learning_rate': 1.475e-06, 'epoch': 4.26, 'step': 170500},\n",
       " {'loss': 0.3036, 'learning_rate': 1.45e-06, 'epoch': 4.28, 'step': 171000},\n",
       " {'loss': 0.2915, 'learning_rate': 1.425e-06, 'epoch': 4.29, 'step': 171500},\n",
       " {'loss': 0.3002,\n",
       "  'learning_rate': 1.4000000000000001e-06,\n",
       "  'epoch': 4.3,\n",
       "  'step': 172000},\n",
       " {'loss': 0.299,\n",
       "  'learning_rate': 1.3750000000000002e-06,\n",
       "  'epoch': 4.31,\n",
       "  'step': 172500},\n",
       " {'loss': 0.3096,\n",
       "  'learning_rate': 1.3500000000000002e-06,\n",
       "  'epoch': 4.33,\n",
       "  'step': 173000},\n",
       " {'loss': 0.2996,\n",
       "  'learning_rate': 1.3250000000000002e-06,\n",
       "  'epoch': 4.34,\n",
       "  'step': 173500},\n",
       " {'loss': 0.3027, 'learning_rate': 1.3e-06, 'epoch': 4.35, 'step': 174000},\n",
       " {'loss': 0.2981, 'learning_rate': 1.275e-06, 'epoch': 4.36, 'step': 174500},\n",
       " {'loss': 0.3042, 'learning_rate': 1.25e-06, 'epoch': 4.38, 'step': 175000},\n",
       " {'loss': 0.3005,\n",
       "  'learning_rate': 1.2250000000000001e-06,\n",
       "  'epoch': 4.39,\n",
       "  'step': 175500},\n",
       " {'loss': 0.3105,\n",
       "  'learning_rate': 1.2000000000000002e-06,\n",
       "  'epoch': 4.4,\n",
       "  'step': 176000},\n",
       " {'loss': 0.3077, 'learning_rate': 1.175e-06, 'epoch': 4.41, 'step': 176500},\n",
       " {'loss': 0.3002,\n",
       "  'learning_rate': 1.1500000000000002e-06,\n",
       "  'epoch': 4.42,\n",
       "  'step': 177000},\n",
       " {'loss': 0.3029, 'learning_rate': 1.125e-06, 'epoch': 4.44, 'step': 177500},\n",
       " {'loss': 0.3053, 'learning_rate': 1.1e-06, 'epoch': 4.45, 'step': 178000},\n",
       " {'loss': 0.3105, 'learning_rate': 1.075e-06, 'epoch': 4.46, 'step': 178500},\n",
       " {'loss': 0.3042,\n",
       "  'learning_rate': 1.0500000000000001e-06,\n",
       "  'epoch': 4.47,\n",
       "  'step': 179000},\n",
       " {'loss': 0.3002, 'learning_rate': 1.025e-06, 'epoch': 4.49, 'step': 179500},\n",
       " {'loss': 0.3055,\n",
       "  'learning_rate': 1.0000000000000002e-06,\n",
       "  'epoch': 4.5,\n",
       "  'step': 180000},\n",
       " {'loss': 0.2944,\n",
       "  'learning_rate': 9.750000000000002e-07,\n",
       "  'epoch': 4.51,\n",
       "  'step': 180500},\n",
       " {'loss': 0.3061,\n",
       "  'learning_rate': 9.500000000000001e-07,\n",
       "  'epoch': 4.53,\n",
       "  'step': 181000},\n",
       " {'loss': 0.3108, 'learning_rate': 9.25e-07, 'epoch': 4.54, 'step': 181500},\n",
       " {'loss': 0.2981,\n",
       "  'learning_rate': 9.000000000000001e-07,\n",
       "  'epoch': 4.55,\n",
       "  'step': 182000},\n",
       " {'loss': 0.3027, 'learning_rate': 8.75e-07, 'epoch': 4.56, 'step': 182500},\n",
       " {'loss': 0.3105,\n",
       "  'learning_rate': 8.500000000000001e-07,\n",
       "  'epoch': 4.58,\n",
       "  'step': 183000},\n",
       " {'loss': 0.3049,\n",
       "  'learning_rate': 8.250000000000001e-07,\n",
       "  'epoch': 4.59,\n",
       "  'step': 183500},\n",
       " {'loss': 0.3041,\n",
       "  'learning_rate': 8.000000000000001e-07,\n",
       "  'epoch': 4.6,\n",
       "  'step': 184000},\n",
       " {'loss': 0.3028,\n",
       "  'learning_rate': 7.750000000000001e-07,\n",
       "  'epoch': 4.61,\n",
       "  'step': 184500},\n",
       " {'loss': 0.3048, 'learning_rate': 7.5e-07, 'epoch': 4.62, 'step': 185000},\n",
       " {'loss': 0.3042, 'learning_rate': 7.25e-07, 'epoch': 4.64, 'step': 185500},\n",
       " {'loss': 0.2968,\n",
       "  'learning_rate': 7.000000000000001e-07,\n",
       "  'epoch': 4.65,\n",
       "  'step': 186000},\n",
       " {'loss': 0.3014,\n",
       "  'learning_rate': 6.750000000000001e-07,\n",
       "  'epoch': 4.66,\n",
       "  'step': 186500},\n",
       " {'loss': 0.2993, 'learning_rate': 6.5e-07, 'epoch': 4.67, 'step': 187000},\n",
       " {'loss': 0.3016, 'learning_rate': 6.25e-07, 'epoch': 4.69, 'step': 187500},\n",
       " {'loss': 0.3044,\n",
       "  'learning_rate': 6.000000000000001e-07,\n",
       "  'epoch': 4.7,\n",
       "  'step': 188000},\n",
       " {'loss': 0.3056,\n",
       "  'learning_rate': 5.750000000000001e-07,\n",
       "  'epoch': 4.71,\n",
       "  'step': 188500},\n",
       " {'loss': 0.303, 'learning_rate': 5.5e-07, 'epoch': 4.72, 'step': 189000},\n",
       " {'loss': 0.2974,\n",
       "  'learning_rate': 5.250000000000001e-07,\n",
       "  'epoch': 4.74,\n",
       "  'step': 189500},\n",
       " {'loss': 0.3031,\n",
       "  'learning_rate': 5.000000000000001e-07,\n",
       "  'epoch': 4.75,\n",
       "  'step': 190000},\n",
       " {'loss': 0.3124,\n",
       "  'learning_rate': 4.7500000000000006e-07,\n",
       "  'epoch': 4.76,\n",
       "  'step': 190500},\n",
       " {'loss': 0.3047,\n",
       "  'learning_rate': 4.5000000000000003e-07,\n",
       "  'epoch': 4.78,\n",
       "  'step': 191000},\n",
       " {'loss': 0.3029,\n",
       "  'learning_rate': 4.2500000000000006e-07,\n",
       "  'epoch': 4.79,\n",
       "  'step': 191500},\n",
       " {'loss': 0.3034,\n",
       "  'learning_rate': 4.0000000000000003e-07,\n",
       "  'epoch': 4.8,\n",
       "  'step': 192000},\n",
       " {'loss': 0.2989, 'learning_rate': 3.75e-07, 'epoch': 4.81, 'step': 192500},\n",
       " {'loss': 0.3023,\n",
       "  'learning_rate': 3.5000000000000004e-07,\n",
       "  'epoch': 4.83,\n",
       "  'step': 193000},\n",
       " {'loss': 0.3085, 'learning_rate': 3.25e-07, 'epoch': 4.84, 'step': 193500},\n",
       " {'loss': 0.3057,\n",
       "  'learning_rate': 3.0000000000000004e-07,\n",
       "  'epoch': 4.85,\n",
       "  'step': 194000},\n",
       " {'loss': 0.2977, 'learning_rate': 2.75e-07, 'epoch': 4.86, 'step': 194500},\n",
       " {'loss': 0.2979,\n",
       "  'learning_rate': 2.5000000000000004e-07,\n",
       "  'epoch': 4.88,\n",
       "  'step': 195000},\n",
       " {'loss': 0.3026,\n",
       "  'learning_rate': 2.2500000000000002e-07,\n",
       "  'epoch': 4.89,\n",
       "  'step': 195500},\n",
       " {'loss': 0.2981,\n",
       "  'learning_rate': 2.0000000000000002e-07,\n",
       "  'epoch': 4.9,\n",
       "  'step': 196000},\n",
       " {'loss': 0.3096,\n",
       "  'learning_rate': 1.7500000000000002e-07,\n",
       "  'epoch': 4.91,\n",
       "  'step': 196500},\n",
       " {'loss': 0.2944,\n",
       "  'learning_rate': 1.5000000000000002e-07,\n",
       "  'epoch': 4.92,\n",
       "  'step': 197000},\n",
       " {'loss': 0.3048,\n",
       "  'learning_rate': 1.2500000000000002e-07,\n",
       "  'epoch': 4.94,\n",
       "  'step': 197500},\n",
       " {'loss': 0.2946,\n",
       "  'learning_rate': 1.0000000000000001e-07,\n",
       "  'epoch': 4.95,\n",
       "  'step': 198000},\n",
       " {'loss': 0.2965,\n",
       "  'learning_rate': 7.500000000000001e-08,\n",
       "  'epoch': 4.96,\n",
       "  'step': 198500},\n",
       " {'loss': 0.2995,\n",
       "  'learning_rate': 5.0000000000000004e-08,\n",
       "  'epoch': 4.97,\n",
       "  'step': 199000},\n",
       " {'loss': 0.3009,\n",
       "  'learning_rate': 2.5000000000000002e-08,\n",
       "  'epoch': 4.99,\n",
       "  'step': 199500},\n",
       " {'loss': 0.3104, 'learning_rate': 0.0, 'epoch': 5.0, 'step': 200000},\n",
       " {'train_runtime': 45336.9633,\n",
       "  'train_samples_per_second': 141.165,\n",
       "  'train_steps_per_second': 4.411,\n",
       "  'total_flos': 1.8828555422659584e+17,\n",
       "  'train_loss': 0.330487278137207,\n",
       "  'epoch': 5.0,\n",
       "  'step': 200000}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dda16ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 14908\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='466' max='466' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [466/466 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f276e48846a44168da1d8a96a9217b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ed22f259f24ab88604ae1f54c8a617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab6f7d07fce47948fca8031abb51738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc75317f9ea5415b81b642ec85dc16a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(full_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12a529c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 1.3172221 , -1.2661456 ],\n",
      "       [ 0.46419087, -0.46328586],\n",
      "       [-2.99875   ,  2.7137077 ],\n",
      "       ...,\n",
      "       [-1.691302  ,  1.5905378 ],\n",
      "       [ 1.7177359 , -1.6653658 ],\n",
      "       [ 0.52410513, -0.49882385]], dtype=float32), label_ids=array([1, 0, 1, ..., 1, 1, 0]), metrics={'test_loss': 0.4353238344192505, 'test_accuracy': 0.8099007244432519, 'test_recall': 0.8354814253222138, 'test_precision': 0.8892475287472261, 'test_f1': 0.8615264340858009, 'test_runtime': 40.7726, 'test_samples_per_second': 365.638, 'test_steps_per_second': 11.429})\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59b6d7",
   "metadata": {},
   "source": [
    "# Getting validation set scores for different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f30d2384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file Model_2/electra_checkpoint/checkpoint-160500/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"Model_2/electra_checkpoint/checkpoint-160500\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file Model_2/electra_checkpoint/checkpoint-160500/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at Model_2/electra_checkpoint/checkpoint-160500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"Model_2/electra_checkpoint/checkpoint-160500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df3a8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_train_dataset,\n",
    "    eval_dataset=full_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9810721b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 320000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 13:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_epoch1 = trainer.predict(full_val_dataset) #40500 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8de4417e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-0.69670856,  0.6278692 ],\n",
      "       [ 0.31944656, -0.33224612],\n",
      "       [ 1.748635  , -1.6630782 ],\n",
      "       ...,\n",
      "       [ 1.3376508 , -1.2933408 ],\n",
      "       [ 1.0504603 , -1.0090101 ],\n",
      "       [-2.9357631 ,  2.7119384 ]], dtype=float32), label_ids=array([1, 1, 0, ..., 0, 0, 1]), metrics={'test_loss': 0.3560219705104828, 'test_accuracy': 0.846765625, 'test_recall': 0.809925, 'test_precision': 0.8743480578364629, 'test_f1': 0.8409044453312827, 'test_runtime': 844.2099, 'test_samples_per_second': 379.053, 'test_steps_per_second': 11.845})\n"
     ]
    }
   ],
   "source": [
    "print(predictions_epoch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34b7abd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 320000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 13:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_epoch2 = trainer.predict(full_val_dataset) #79500 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1d191ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-1.2658587,  1.1281052],\n",
      "       [ 0.5234114, -0.5097152],\n",
      "       [ 1.7875103, -1.6892575],\n",
      "       ...,\n",
      "       [ 1.0529957, -1.0021056],\n",
      "       [ 1.1515462, -1.0941873],\n",
      "       [-3.004703 ,  2.783153 ]], dtype=float32), label_ids=array([1, 1, 0, ..., 0, 0, 1]), metrics={'test_loss': 0.34015220403671265, 'test_accuracy': 0.855171875, 'test_recall': 0.83278125, 'test_precision': 0.8718225537344195, 'test_f1': 0.8518548116419199, 'test_runtime': 844.3657, 'test_samples_per_second': 378.983, 'test_steps_per_second': 11.843})\n"
     ]
    }
   ],
   "source": [
    "print(predictions_epoch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1bf5012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 320000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 13:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_epoch3 = trainer.predict(full_val_dataset) #120000 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80ae8f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-1.4749368,  1.2924808],\n",
      "       [ 0.3211063, -0.3160295],\n",
      "       [ 1.7694764, -1.6648208],\n",
      "       ...,\n",
      "       [ 1.5603765, -1.484025 ],\n",
      "       [ 1.4992547, -1.4257147],\n",
      "       [-3.1185923,  2.8918579]], dtype=float32), label_ids=array([1, 1, 0, ..., 0, 0, 1]), metrics={'test_loss': 0.3388102650642395, 'test_accuracy': 0.85779375, 'test_recall': 0.838125, 'test_precision': 0.8724447972102586, 'test_f1': 0.8549406131855941, 'test_runtime': 833.0859, 'test_samples_per_second': 384.114, 'test_steps_per_second': 12.004})\n"
     ]
    }
   ],
   "source": [
    "print(predictions_epoch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4aed1f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 320000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 13:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_epoch4 = trainer.predict(full_val_dataset) #160500 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "638266db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-1.5577074 ,  1.3627528 ],\n",
      "       [ 0.11364885, -0.12057789],\n",
      "       [ 1.4910351 , -1.4090536 ],\n",
      "       ...,\n",
      "       [ 1.5378461 , -1.470245  ],\n",
      "       [ 1.3836223 , -1.3278061 ],\n",
      "       [-3.2834418 ,  3.0488112 ]], dtype=float32), label_ids=array([1, 1, 0, ..., 0, 0, 1]), metrics={'test_loss': 0.3345937132835388, 'test_accuracy': 0.8594, 'test_recall': 0.85968125, 'test_precision': 0.8591979511524768, 'test_f1': 0.8594395326314473, 'test_runtime': 832.4901, 'test_samples_per_second': 384.389, 'test_steps_per_second': 12.012})\n"
     ]
    }
   ],
   "source": [
    "print(predictions_epoch4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a448f337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 320000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 13:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_epoch5 = trainer.predict(full_val_dataset) #199500 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6253826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-1.5769312 ,  1.3791589 ],\n",
      "       [ 0.18935488, -0.19263446],\n",
      "       [ 1.583908  , -1.4965011 ],\n",
      "       ...,\n",
      "       [ 1.6371045 , -1.5684509 ],\n",
      "       [ 1.6357325 , -1.5725911 ],\n",
      "       [-3.3241131 ,  3.0859528 ]], dtype=float32), label_ids=array([1, 1, 0, ..., 0, 0, 1]), metrics={'test_loss': 0.33586248755455017, 'test_accuracy': 0.860240625, 'test_recall': 0.849525, 'test_precision': 0.8681301134948362, 'test_f1': 0.8587267943052268, 'test_runtime': 833.6574, 'test_samples_per_second': 383.851, 'test_steps_per_second': 11.995})\n"
     ]
    }
   ],
   "source": [
    "print(predictions_epoch5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fea32809",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = [0.3385,0.3336,0.314,0.3048,0.3009]\n",
    "val_loss = [0.3560219705104828,0.34015220403671265,0.3388102650642395,0.3345937132835388,0.33586248755455017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f426b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_F1 = [0.8409044453312827,0.8518548116419199,0.8549406131855941,0.8594395326314473,0.8587267943052268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a74f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = [0.846765625,0.855171875, 0.85779375,0.8594,0.860240625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9abddff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "RANGE = range(1, 6)\n",
    "plt.plot(RANGE, train_loss,\n",
    "         label = \"Training Loss\")\n",
    "plt.plot(RANGE, val_loss, label = \"Validation Loss\")\n",
    "\n",
    "plt.xticks(RANGE)\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('NoisyLossPlot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b210464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAG3CAYAAAAdNMCcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABOjElEQVR4nO3dd5heZZ3/8fd3WiaZ9B5SSKWEAIFM6L2ZYAE7KEoiCIjY1nV1XXYX2d3fqmtfJVIkARQQO66EohJAQciEUCahpddJ78lk2v37Yx5wSCNAnjlT3q/rmivPc855znyODjCfnPvcd6SUkCRJkiSpqYKsA0iSJEmSWh7LoiRJkiRpN5ZFSZIkSdJuLIuSJEmSpN1YFiVJkiRJu7EsSpIkSZJ2U5R1gCz17t07DR06NOsYkiRJkpSJWbNmrU0p9dnTvnZdFocOHUpFRUXWMSRJkiQpExGxeG/7HIYqSZIkSdqNZVGSJEmStJu8lsWImBARL0XEvIj4yh72D4mIhyNidkQ8FxHnN9l3VEQ8ERFzIuL5iCjNbR+Xez8vIn4QEZHb3jMiHoqIV3J/9sjntUmSJElSW5a3shgRhcCPgInAaODiiBi9y2HXAveklI4BLgJuyH22CPgpcFVK6QjgDKA295kpwCeBUbmvCbntXwH+lFIaBfwp916SJEmS9Bbk887iccC8lNKClFINcDdwwS7HJKBr7nU3YEXu9XnAcymlZwFSSutSSvURMQDomlL6W0opAbcDF+Y+cwFwW+71bU22S5IkSZLepHyWxYHA0ibvl+W2NXUdcElELAPuAz6T234IkCLigYh4OiL+qck5l+3lnP1SSitzr6uAfnsKFRFXRERFRFSsWbPmLVyWJEmSJLV9WU9wczEwLaU0CDgfuCMiCmhc0uMU4KO5P98bEWfv70lzdx3TXvbdlFIqTymV9+mzx+VEJEmSJKndy2dZXA4MbvJ+UG5bU5cB9wCklJ4ASoHeNN4xfDSltDaltJ3Gu47H5j4/aC/nXJUbpkruz9UH9GokSZIkqR3JZ1mcCYyKiGERUULjBDb37nLMEuBsgIg4nMayuAZ4ADgyIjrlJrs5HZibG2a6OSJOyM2C+nHgd7lz3Qtcmnt9aZPtkiRJkqQ3qShfJ04p1UXENTQWv0Lg1pTSnIi4HqhIKd0LfBG4OSK+QOOw0Um5IaQbIuI7NBbOBNyXUvpD7tRXA9OAjsD03BfA14F7IuIyYDHwoXxdmyRJkiS1ddHYzdqn8vLyVFFRkXUMSZIkScpERMxKKZXvaV/WE9xIkiRJklogy6IkSZIkaTeWRUmSJEnSbiyLkiRJkqTdWBYlSZLUbLburGPDthoaGtrvJItSa5G3pTMkSZKkVy1dv50bH53PPRXLqKlroCCgW8dienQqoXunV/8soWdZMd07ldCjUwk9OhXntv39dUmR9zqk5mJZlCRJUt68VLWFKTPm8fvnVlIQ8P5jBzGqXxc2bq9hw/YaNmyvZeP2GlZuqmbuys1s2F5DdW3DXs9XVlLYWCbLinOF8u9FskenYnqUlby2vXvufVlJIRHRjFcttQ2WRUmSJB1wsxZvYMqMefzxhdV0Kilk8klDufzU4fTvVvqGn62urW8skttqc4UyVyq3/b1crs9tW7J+Oxu21bC5um6v5yspLGhy9zJXMpuUzabbuncqoWenErp2LKawwIKp9s2yKEmSpAMipcSjr6zlhofn8eTC9XTvVMznzxnFpScOpUdZyX6fp7S4kAHdOjKgW8f9/kxdfQMbd9Tm7ljWsmFbDRu3N5bN9dtr2Jgrnhu31zJ/zVY2LG58XbeXZydjl2GyPXPDZF+9e/lawWxSPLt3KqZDUeF+Z5ZaOsuiJEmS3pb6hsT9lVVMeWQelcs3079rKde+83AuPm4IZR2a59fNosICenfuQO/OHfb7Mykltuyse61Ivva1rUnpzG1buamaF1ZuZsP2WnbU1u/1nJ1KCncpkE2evXytaOZKZ6cSh8mqRbMsSpIk6S2pqWvgN7OXceMjC1iwdhvDepfxjfcfyYXHDGwVd9gigq6lxXQtLWZIr077/bnq2no2bq9l/baa15XKpnc1Xx06u3T9djZsr2XTjtq9nq+4MF5XKnt0KqZnWcku214/+U83h8mqGVgWJUmS9KZsr6njzieXcMtjC6naXM0RB3XlRx85lglj+reLAlNaXEj/boX79fzlq+rqG9i0o/a1Zy5fu2vZ5DnMVwvmgjXbmLV4Ixu31+xzmGzX0uLXTerz96Gxe9rW+Lq0uOWXeLUclkVJkiTtl43ba7jt8cVMe3whG7bXctywnnzjA0dx2qjeDqN8A0WFBfTq3IFeb3KY7NaddX9/9rLJc5ivTfST27ZqczUvVW1hw/Yatte88TDZ3Sf8+fvQ2Fe39cw9m9m5Q5H//7ZTlkVJkiTt06rN1dzy2ALufHIJ22rqOfuwvlx95gjGHdwz62htWkTQpbSYLqXFDO755ofJvvq85cbtf5/cZ/22129bvnEH67fVsLm6lrTnm5gUFwbdOjZ9zvL1z2M2LZtNh862h7vMbZ1lUZIkSXu0aO02bnx0Pr+atZy6hgbeffRBfOqMERzWv2vW0bQPb2WYbH1Dyg2TzT17ua22cRbZJncxX922cO02nt7eOEy2tn4vDRPoWlr0umcvXy2YTZ+9fK1g5gqow2RbFsuiJEmSXmfOik1MmTGf+55fSVFhAR8sH8SVp414U5PAqHUpLAh6ljUOPd1fKSW21dS/bkKfjU2ew2y6bc3Wnby8aisbt9ewbR/DZDsWF+5WIHctla+uhdmjUwndy4rp4jDZvLEsSpIkCYCnFq7nhhnzmPHSGjp3KOKTpw3nspOH0bfr/t+hUvsREXTuUETnDkVvapjszromw2R3XaZklwl/VmzczIbtNWzasfdhskUFsdtEPq8WyR65Ytn9tUl/Gstm947FFBUWHKD/Jdouy6IkSVI7llLi4ZdWc8PD86lYvIGeZSX843mH8LEThtKtU3HW8dQGdSgqpF/XQvq9ib+EqG9IbN7x97uVG3Z59rLptsXrtvPM0o1s3F5LTX3DXs/ZtbRo93UvX72LucuEPz1zs8u2t2GylkVJkqR2qK6+gfsqq7jh4Xm8WLWFg7qVct27R/Ph8UPoWNK+fiFWy1dYEI13Bt/kMNntNfW7zCLb5HWT4bLrttYwb/VWNmzb9zDZ0uKCPTx7ucuEP2WvHzrbtbT1DpO1LEqSJLUj1bX1/OrpZdz06AIWr9vOiD5l/M8HjuKCsQMpKXJYntqOiKCsQxFlHYoY/CYm7t1ZV8+m7bWvFcnGJUqaTP7TZNmSlblhshv3MUy2sCDo0amY8oN78uOPjTswF9dMLIuSJEntwNadddz55GJueWwhq7fs5KhB3fjxJcdy3uj+FLjEgfSaDkWF9O1a+Kae1W1oSGyubiyYjXcyX//s5YbttfTtsv9rbLYUlkVJkqQ2bP22Gqb9dSG3PbGYTTtqOWlEL77zobGcPLJXqx0aJ7U0BQXROHFOpxKG9S7LOs4BY1mUJElqg1Zs3MHNjy3g7qeWsqO2nvNG9+PqM0cydnD3rKNJaiUsi5IkSW3I/DVb+fGM+fz2meU0JLhg7EF86vQRjOrXJetokloZy6IkSVIb8PyyTdwwYx73z6mipLCAjxw3hE+eNpxBPfZ//TtJasqyKEmS1EqllHhiwTqmzJjPY6+spUuHIq4+YwSTTx5G786tbzINSS2LZVGSJKmVaWhI/PGFVdwwYz7PLN1I784d+PKEw/joCUPoWlqcdTxJbYRlUZIkqZWoq2/g98+tYMqM+by8aiuDenTkPy4cwwfHDaK0uDDreJLaGMuiJElSC1ddW88vKpZy46MLWLZhB4f068x3P3w07z7qIIoKC7KOJ6mNsixKkiS1UJura/np3xZz618WsnZrDccM6c6/v/sIzj6sLwUFrpEoKb8si5IkSS3M2q07ufUvC7njicVs2VnHqaN6c/UZIzlheE8iLImSmodlUZIkqYVYtmE7Nz26gJ/PXEpNfQMTx/TnU6eP5MhB3bKOJqkdsixKkiRl7JVVW5gyYz6/e3YFAbz3mIFcdcYIRvTpnHU0Se2YZVGSJCkjs5ds4IYZ83lo7io6Fhfy8RMP5pOnDueg7h2zjiZJlkVJkqTmlFLir/PWccOMeTw+fx1dS4v47FkjmXTyMHqWlWQdT5JeY1mUJElqBg0NiQfnVnHDjPk8t2wTfbt04KvnH8ZHjj+Yzh38lUxSy+O/mSRJkvKotr6B385ezo8fmc/8Nds4uFcn/t97j+R9xw6ktLgw63iStFeWRUmSpDzYUVPP3TOXcPOjC1ixqZrD+nfhBxcfw/lj+lNUWJB1PEl6Q5ZFSZKkA2jT9lpuf2IRUx9fxPptNYwf2oP/eu+RnHFoH9dIlNSqWBYlSZIOgNWbq/nJXxbysyeXsHVnHWce2oerzxzJ+KE9s44mSW+JZVGSJOltWLJuOzc+Op9fzFpGXX0D7zzqID51+ghGH9Q162iS9LbktSxGxATg+0AhcEtK6eu77B8C3AZ0zx3zlZTSfRExFHgBeCl36N9SSldFRBfgsSanGAT8NKX0+YiYBPwPsDy374cppVvycmGSJKnde7FqM1NmzOf3z66gqKCA948byJWnjWBo77Kso0nSAZG3shgRhcCPgHOBZcDMiLg3pTS3yWHXAveklKZExGjgPmBobt/8lNLYpudMKW0BXtsWEbOAXzc55OcppWsO8KVIkiS9Ztbi9dzw8Hz+9OJqOpUUctkpw7j81OH061qadTRJOqDyeWfxOGBeSmkBQETcDVwANC2LCXh1jEY3YMX+njwiDgH68vo7jZIkSQdcSolHXl7DDTPm89TC9fToVMwXzjmES086mO6dSrKOJ0l5kc+yOBBY2uT9MuD4XY65DngwIj4DlAHnNNk3LCJmA5uBa1NKu5bCi2i8k5iabHt/RJwGvAx8IaW0dJfPEBFXAFcADBky5E1flCRJaj/qGxLTK1cyZcZ85qzYTP+upfzru0Zz8XGD6VTi1A+S2ras/y13MTAtpfTtiDgRuCMixgArgSEppXURMQ74bUQckVLa3OSzFwEfa/L+98BdKaWdEXEljc9CnrXrN0wp3QTcBFBeXp523S9JkrSzrp7fPL2cGx9dwMK12xjeu4xvvv8oLjxmICVFrpEoqX3IZ1lcDgxu8n4Qf5985lWXARMAUkpPREQp0DultBrYmds+KyLmA4cAFQARcTRQlFKa9eqJUkrrmpz3FuCbB/ZyJElSW7dtZx13PbWEWx5bSNXmasYM7MoNHz2WdxzRn8IC10iU1L7ksyzOBEZFxDAaS+JFwEd2OWYJcDYwLSIOB0qBNRHRB1ifUqqPiOHAKGBBk89dDNzV9EQRMSCltDL39j00zqYqSZL0hjZsq2Ha44u47YlFbNxey/HDevLNDxzFqaN6E2FJlNQ+5a0sppTqIuIa4AEal8W4NaU0JyKuBypSSvcCXwRujogv0DjZzaSUUso9d3h9RNQCDcBVKaX1TU7/IeD8Xb7lZyPiPUAdsB6YlK9rkyRJbUPVpmpueWwBdz61hO019ZxzeF8+dcZIxh3cI+tokpS5eP38MO1LeXl5qqioyDqGJElqZgvXbuPGR+bzq6eX0ZDg3UcN4FNnjOTQ/l2yjiZJzSoiZqWUyve0L+sJbiRJkppN5fJNTHlkPtOfX0lRYQEfHj+YK08bweCenbKOJkktjmVRkiS1aSklnlq4nhtmzOeRl9fQuUMRV5w2gk+cMpS+XUqzjidJLZZlUZIktUkpJf784mpumDGfWYs30KushC+941AuOeFgunUszjqeJLV4lkVJktSm1NU38IfnVzJlxnxerNrCwO4d+dp7juBD5YPpWFKYdTxJajUsi5IkqU2orq3nl7OWcdOjC1iyfjsj+3bmWx88mgvGHkRxYUHW8SSp1bEsSpKkVm3rzjp+9rfF3PKXhazZspOjB3Xjq+eP47zR/SgocI1ESXqrLIuSJKlVWrd1J9MeX8Rtjy9ic3UdJ4/sxfc+PJaTRvQiwpIoSW+XZVGSJLUqyzfu4OZHF3D3zCVU1zbwjiP6cfUZIzl6cPeso0lSm2JZlCRJrcK81Vv58SPz+e3s5QBcMHYgnzpjOCP7dsk4mSS1TZZFSZLUoj23bCM3PDyfB+ZW0aGogEtOOJjLTx3GoB6dso4mSW2aZVGSJLU4KSWemL+OG2bM5y/z1tKltIhPnzGSSScPpXfnDlnHk6R2wbIoSZJajIaGxB9fWMWPZszn2aUb6d25A1+ecBiXnDCELqXFWceTpHbFsihJkjJXW9/A759dwZQZ83ll9VYG9+zIf1w4hg+OG0RpcWHW8SSpXbIsSpKkzFTX1nNPxVJufGQByzfu4NB+Xfjeh8fyrqMGUFRYkHU8SWrXLIuSJKnZba6u5Y4nFjP1rwtZu7WGY4d052vvOYKzDutLQYFrJEpSS2BZlCRJzWbNlp3c+teF/PSJxWzZWcdph/Th6jNGcPywnkRYEiWpJbEsSpKkvFu6fjs3PbqAeyqWUlPfwPljBvCpM0YwZmC3rKNJkvbCsihJkvLm5VVbmDJjPvc+u4KCgPcdM4grTx/O8D6ds44mSXoDlkVJknTAzV6ygRtmzOehuavoWFzIpJOGcvmpwxjQrWPW0SRJ+8myKEmSDoiUEn+Zt5YbHp7PEwvW0a1jMZ89exSTThpKz7KSrONJkt4ky6IkSXpbGhoSD8yp4oYZ83l++Sb6de3Av5x/OBcfP4TOHfxVQ5JaK/8NLkmS3pKaugZ++8xyfvzIfBas2cbQXp347/cdyfuOHUiHosKs40mS3ibLoiRJelO219Rx91NLueWxBazYVM3hA7ryvxcfw/lHDqDQNRIlqc2wLEqSpP2yaXsttz2xiKl/XciG7bUcN7Qn//W+IznjkD6ukShJbZBlUZIk7dPqzdXc8peF/Oxvi9lWU89Zh/Xl6jNGUD60Z9bRJEl5ZFmUJEl7tHjdNn78yAJ+NWsZdQ0NvOuog/jUGSM4fEDXrKNJkpqBZVGSJL3OCys3c8OM+fzhuRUUFRTw/nGDuPK04QztXZZ1NElSM7IsSpIkACoWreeGGfP584urKSsp5PJTh3PZKcPo17U062iSpAxYFiVJasdSSsx4eQ1THp7PU4vW06NTMf9w7iFceuJQunUqzjqeJClDlkVJktqh+obEfc+vZMqM+cxduZkB3Ur5t3eN5qLjBtOpxF8PJEmWRUmS2pWddfX8+unl3PjIfBat287wPmV88wNHceHYgZQUFWQdT5LUglgWJUlqB7btrOOup5Zw82MLWLV5J0cO7MaUjx7LeUf0p7DANRIlSbuzLEqS1IZt2FbDtMcXcdsTi9i4vZYThvfkWx88mlNG9ibCkihJ2jvLoiRJbdDKTTu45bGF3PnkEnbU1nPO4f24+swRHDukR9bRJEmthGVRkqQ2ZMGardz4yAJ+PXsZDQnec/RBXHX6CA7t3yXraJKkVsayKElSG1C5fBNTZsznvsqVFBcWcNH4IVxx2nAG9+yUdTRJUitlWZQkqZVKKfHkwvXcMGM+j768hi4dirjq9BF84uRh9OnSIet4kqRWzrIoSVIrk1LiTy+s5oYZ83h6yUZ6lZXwpXccysdOPJiupcVZx5MktRGWRUmSWom6+gb+77mVTJkxn5dWbWFg945cf8ERfKh8MKXFhVnHkyS1MZZFSZJauOraen4xaxk3PTqfpet3MKpvZ77zoaN599EHUVxYkHU8SVIbZVmUJKmF2lJdy8+eXMJP/rKQNVt2cvTg7vzrO0dzzuH9KChwjURJUn7ltSxGxATg+0AhcEtK6eu77B8C3AZ0zx3zlZTSfRExFHgBeCl36N9SSlflPjMDGADsyO07L6W0OiI6ALcD44B1wIdTSovydnGSJOXJuq07mfrXRdz+xCI2V9dxysjefP/DYzlxRC8iLImSpOaRt7IYEYXAj4BzgWXAzIi4N6U0t8lh1wL3pJSmRMRo4D5gaG7f/JTS2L2c/qMppYpdtl0GbEgpjYyIi4BvAB8+MFcjSVL+Ld+4g5sfXcDdM5ews66Bd4zuz6fOGMHRg7tnHU2S1A7l887iccC8lNICgIi4G7gAaFoWE9A197obsOJtfL8LgOtyr38J/DAiIqWU3sY5JUnKu3mrtzBlxgJ+98xyAC48ZiBXnT6CkX07Z5xMktSe5bMsDgSWNnm/DDh+l2OuAx6MiM8AZcA5TfYNi4jZwGbg2pTSY032TY2IeuBXwH/mCuFr3y+lVBcRm4BewNqm3zAirgCuABgyZMjbukBJkt6qlBLPLtvElBnzeHDuKjoUFXDJCQfzydOGM7B7x6zjSZKU+QQ3FwPTUkrfjogTgTsiYgywEhiSUloXEeOA30bEESmlzTQOQV0eEV1oLIsfo/FZxf2SUroJuAmgvLzcu46SpGaTUuL55ZuYXlnF/ZVVLFy7jS6lRVxz5kgmnTSUXp07ZB1RkqTX5LMsLgcGN3k/KLetqcuACQAppSciohTonVJaDezMbZ8VEfOBQ4CKlNLy3PYtEXEnjcNdb2/y/ZZFRBGNw1rX5eviJEnaHw0NiaeXbHitIC7fuIPCguDE4b247JRhXDD2ILqUFmcdU5Kk3eSzLM4ERkXEMBqL3EXAR3Y5ZglwNjAtIg4HSoE1EdEHWJ9Sqo+I4cAoYEGuBHZPKa2NiGLgXcAfc+e6F7gUeAL4APBnn1eUJGWhrr6BpxauZ3plFQ/MqWL1lp2UFBZwyqjefO6cUZx7eD96lJVkHVOSpH3KW1nMPTd4DfAAjcti3JpSmhMR19N4h/Be4IvAzRHxBRonu5mUUkoRcRpwfUTUAg3AVSml9RFRBjyQK4qFNBbFm3Pf8ic0DmOdB6ynsZxKktQsauoaeHz+Wu6vrOLBuatYv62G0uICzjikLxOP7M+Zh/Wlq3cQJUmtSLTnm2/l5eWpomLXFTgkSdo/1bX1PPryGu6vrOKhF1axpbqOzh2KOOuwvkwc05/TD+1Dp5KspweQJGnvImJWSql8T/v8L5gkSW/Ctp11PPzSaqZXVvHwi6vZXlNPt47FnDe6PxPH9OeUUb0pLS7MOqYkSW+bZVGSpDewaUctf3phFdMrq3j05TXsrGugd+cSLhg7kIlj+nPiiF4UFxZkHVOSpAPKsihJ0h6s27qTh+Y2FsTH56+ltj7Rv2spFx83hAlj+jN+aE8KCyLrmJIk5Y1lUZKknFWbq3lgThXTn6/iyYXraEgwuGdHJp88jAlj+jN2UHcKLIiSpHbCsihJateWbdjO/ZVVTK+s4uklG0gJRvQp4+ozRjJhTH+OOKgrERZESVL7Y1mUJLU7C9ZsZXplFfdXVvH88k0AHD6gK1845xAmjunPqH5dMk4oSVL2LIuSpDYvpcTLq7Zy3/Mrub+yipdWbQHg6MHd+crEw5hwRH+G9i7LOKUkSS2LZVGS1CallKhcvpnplY0FccHabURA+cE9+Nd3jWbCmP4M7N4x65iSJLVYlkVJUpvR0JCYvXQD05+v4v45VSzbsIPCguCE4T2ZfMow3nFEP/p2Kc06piRJrYJlUZLUqtXVN/DUovXcX1nFA3OqWLV5J8WFwSkje/PZs0Zx7uh+9CgryTqmJEmtjmVRktTq1NQ18Pj8tdxfWcWDc1exflsNpcUFnH5IHyaOGcBZh/ela2lx1jElSWrVLIuSpFahuraeR19ew/2VVfzxhVVsrq6jrKSQsw7vx8Qx/Tnj0D50KvE/a5IkHSj+V1WS1GJt21nHwy+tZnplFQ+/uJrtNfV0LS3i3NH9mTimP6eM6k1pcWHWMSVJapMsi5KkFmXTjlr+/OIq7nu+ikdfXsPOugZ6lZVwwdiBTBzTnxNH9KK4sCDrmJIktXmWRUlS5tZvq+GhuVVMr6zir/PWUluf6N+1lIuPG8KEMf0ZP7QnhQWRdUxJktoVy6IkKROrN1fzwJzGgvjkwvXUNyQG9ejI5JOHMWFMf8YO6k6BBVGSpMxYFiVJzWbZhu3cX1nF/ZVVzFqygZRgeJ8yrjp9OBPHDOCIg7oSYUGUJKklsCxKkvJq4dptTK9cyf2VVTy3bBMAh/XvwufPPoSJR/ZnVN/OFkRJklogy6Ik6YBKKfHyqq2vFcQXq7YAcPSgbnx5wmFMHNOfob3LMk4pSZLeiGVRkvS2pZSoXL75tYK4YO02IqD84B7867tGM2FMfwZ275h1TEmS9CZYFiVJb0lDQ2L20g1Mf76K++dUsWzDDgoLghOG92TyKcN4x+h+9O1amnVMSZL0FlkWJUn7ra6+gacWref+yioemFPFqs07KS4MThnZm8+eNYpzRvejZ1lJ1jElSdIBYFmUJO1TTV0DTyxYx/2VK3lwzirWbauhQ1EBpx/Sh/OPHMBZh/ela2lx1jElSdIBZlmUJO2muraex15Zy/TKlfxx7io2V9dRVlLImYf1ZeKYAZxxaB/KOvifEEmS2jL/Sy9JAmDbzjpmvLSG6ZUrefjF1WyrqadraRHnjO7HxDEDOHVUb0qLC7OOKUmSmollUZLasc3VtfzphVVMf76KR15ew866BnqVlfCesQcxYcwAThzei5KigqxjSpKkDFgWJamdWb+thofmVjG9soq/zltLbX2iX9cOXDR+MBPGDOC4YT0pLIisY0qSpIxZFiWpHVi9uZoH5jQWxCcXrqe+ITGoR0cmnTSUCWMGcMzg7hRYECVJUhOWRUlqo5Zv3MH051dyf2UVs5ZsICUY3qeMq04fzsQxAzjioK5EWBAlSdKeWRYlqQ1ZtHYb0yuruL9yJc8u2wTAYf278PmzD2Hikf0Z1bezBVGSJO0Xy6IktWIpJV5ZvZXpz1cxvXIlL1ZtAeDoQd348oTDmDCmP8N6l2WcUpIktUaWRUlqZVJKzFmxmemVK5leWcWCNduIgHFDenDtOw9nwpj+DOrRKeuYkiSplbMsSlIr0NCQmL10I/fnCuKyDTsoLAiOH9aTyScN5R1H9Kdv19KsY0qSpDbEsihJLVR9Q+Kpheu5v3IlD8xZRdXmaooLg5NH9uYzZ43k3NH96VlWknVMSZLURlkWJakFqa1v4PH567i/ciUPzlnFum01dCgq4PRD+vDlIw/lrMP60a1jcdYxJUlSO2BZlKSMVdfW89gra5leuZI/zl3F5uo6ykoKOfOwvkwcM4AzDu1DWQf/dS1JkpqXv31IUga219Tx8ItrmF65kodfXM22mnq6lhZxzuh+TBwzgFNH9aa0uDDrmJIkqR2zLEpSM9lcXcufX1jNfc+v5JGX17CzroFeZSW8Z+xBTBgzgBOH96KkqCDrmJIkSYBlUZLyasO2Gh6au4rplSv5y7y11NYn+nXtwEXjBzNhzADGD+1BUaEFUZIktTyWRUk6wFZvqeaBOau4v3Ilf1uwnvqGxMDuHZl00lAmjBnAMYO7U1AQWceUJEnap7yWxYiYAHwfKARuSSl9fZf9Q4DbgO65Y76SUrovIoYCLwAv5Q79W0rpqojoBPwCGAHUA79PKX0ld65JwP8Ay3Of+WFK6Zb8XZ0k/d3yjTu4v7KK+ytXUrF4AynB8N5lXHnacCaOGcCYgV2JsCBKkqTWI29lMSIKgR8B5wLLgJkRcW9KaW6Tw64F7kkpTYmI0cB9wNDcvvkppbF7OPW3UkoPR0QJ8KeImJhSmp7b9/OU0jX5uB5J2tWitduYniuIzy7bBMBh/bvwubNHMXHMAA7p19mCKEmSWq183lk8DpiXUloAEBF3AxcATctiArrmXncDVuzrhCml7cDDudc1EfE0MOgA55akPUop8crqrUx/vorplSt5sWoLAEcN6sY/TTiUiWMGMKx3WcYpJUmSDox8lsWBwNIm75cBx+9yzHXAgxHxGaAMOKfJvmERMRvYDFybUnqs6QcjojvwbhqHub7q/RFxGvAy8IWUUtPvL0lvWkqJOSs2M71yJdMrq1iwZhsRMG5ID6595+FMGNOfQT06ZR1TkiTpgMt6gpuLgWkppW9HxInAHRExBlgJDEkprYuIccBvI+KIlNJmgIgoAu4CfvDqnUvg98BdKaWdEXEljc9CnrXrN4yIK4ArAIYMGZLv65PUCjU0JJ5ZtpHpz6/k/jlVLF2/g4KAE4b3YvJJQ3nHEf3p27U065iSJEl5lc+yuBwY3OT9IP4++cyrLgMmAKSUnoiIUqB3Smk1sDO3fVZEzAcOASpyn7sJeCWl9L1XT5RSWtfkvLcA39xTqJTSTbnPU15ent7SlUlqc+obEjMXrc9NUlNF1eZqiguDk0f25pozR3Lu6P70LCvJOqYkSVKzyWdZnAmMiohhNJbEi4CP7HLMEuBsYFpEHA6UAmsiog+wPqVUHxHDgVHAq88+/ieNzzde3vREETEgpbQy9/Y9NM6mKkl7VVvfwBPz1zG9soqH5laxdmsNHYoKOO2QPnz5yEM567B+dOtYnHVMSZKkTOStLKaU6iLiGuABGpfFuDWlNCcirgcqUkr3Al8Ebo6IL9A42c2klFLKPXd4fUTUAg3AVSml9RExCPgX4EXg6dwsg68ukfHZiHgPUAesBybl69oktV7VtfX85ZW1TK+s4o8vrGLTjlrKSgo587C+TBjTnzMP7UtZh6xH6EuSJGUvUmq/IzHLy8tTRUXFGx8oqVXbXlPHjJfWML2yij+/sIptNfV0KS3i3MP7MfHIAZw6qjelxYVZx5QkSWp2ETErpVS+p33+9bmkNmlzdS1/fmE10ytX8sjLa6iubaBnWQnvPvogJozpz0kjelNSVJB1TEmSpBbLsiipzdiwrYaH5q5ieuVK/jpvHTX1DfTt0oEPlQ9mwpj+HDe0J0WFFkRJkqT9YVmU1Kqt3lLNg3MaC+LfFqynviExsHtHPn7iwUw8sj/HDO5BQUFkHVOSJKnVsSxKanWWb9zBA7klLmYuXk9KMLx3GVeeNpyJYwYwZmBXchNgSZIk6S2yLEpqFRav28b0yiqmV1bx7NKNABzWvwufO3sUE8cM4JB+nS2IkiRJB5BlUVKL9cqqLa8VxBdWbgbgqEHd+KcJhzLhiP4M79M544SSJEltl2VRUouRUmLOis3cX1nF9MqVzF+zDYBxB/fg2ncezjuO6M/gnp0yTilJktQ+WBYlZW7Dthp+/Mh8pldWsWT9dgoCjh/Wi0tPGso7juhPv66lWUeUJElqdyyLkjK1o6aeSdNmMmf5Jk4e2ZurzxjBuaP70atzh6yjSZIktWuWRUmZqW9IfO7u2Ty3bCM3XjKO847on3UkSZIk5bg6taTM/NcfXuDBuav4t3eNtihKkiS1MJZFSZmY+teF3PrXhXzi5GFMPnlY1nEkSZK0C8uipGb34Jwqrv+/uZw3uh//8s7Ds44jSZKkPbAsSmpWzy7dyGfvns1Rg7rz/YuOobAgso4kSZKkPbAsSmo2S9dv57LbZtKnSwdu+Xg5HUsKs44kSZKkvXA2VEnNYtP2WiZNfYra+sTdk46jTxeXxpAkSWrJvLMoKe921tVzxR0VLF2/g5s+No6RfTtnHUmSJElvwDuLkvIqpcSXf/kcTy5cz/cvGsvxw3tlHUmSJEn7wTuLkvLquw+9zG+fWcE/nncIF4wdmHUcSZIk7SfLoqS8uWfmUn7w53l8uHwwnz5zZNZxJEmS9CZYFiXlxWOvrOGrv3meU0f15j/fO4YIl8iQJElqTSyLkg64F6s2c/VPn2Zk387c8NFjKS70XzWSJEmtzX79BhcRp0TE5NzrPhExLL+xJLVWqzZXM3nqTDp1KOTWSePpUlqcdSRJkiS9BW9YFiPi34EvA/+c21QM/DSfoSS1Tlt31jF56kw276jl1knjOah7x6wjSZIk6S3anzuL7wXeA2wDSCmtALrkM5Sk1qeuvoHP3Pk0L63awg8/eixHHNQt60iSJEl6G/anLNaklBKQACKiLL+RJLU2KSX+/d45PPzSGv7jgjGceWjfrCNJkiTpbdqfsnhPRNwIdI+ITwJ/BG7ObyxJrcmNjy7gZ08u4VNnjOAjxw/JOo4kSZIOgKJ97YzGue5/DhwGbAYOBf4tpfRQM2ST1Ar833Mr+Pr0F3nXUQP40nmHZh1HkiRJB8g+y2JKKUXEfSmlIwELoqTXqVi0nn+451nGD+3Btz54NAUFrqUoSZLUVuzPMNSnI2J83pNIalUWrt3GJ2+vYGD3jtz0sXJKiwuzjiRJkqQDaJ93FnOOBz4aEYtpnBE1aLzpeFRek0lqsdZt3cmkqU8REUybPJ4eZSVZR5IkSdIBtj9l8R15TyGp1aiureeTt1dQtamaOz95Agf3coJkSZKktugNh6GmlBYD3YF3576657ZJamcaGhL/cM8zzF66ke99eCzjDu6RdSRJkiTlyRuWxYj4HPAzoG/u66cR8Zl8B5PU8nzj/he57/kqvjrxcCYeOSDrOJIkScqj/RmGehlwfEppG0BEfAN4AvjffAaT1LLc8bfF3PjoAj5+4sFcfuqwrONIkiQpz/ZnNtQA6pu8r89tk9RO/PnFVfz77yo5+7C+/Nu7RtO4BKskSZLasv25szgVeDIifpN7fyHwk7wlktSiPL9sE9fcOZvRB3XlBxcfQ1Hh/vwdkyRJklq7NyyLKaXvRMQM4JTcpskppdl5TSWpRVi+cQefuG0mPTqVcOul4ynrsD9/vyRJkqS24A1/84uIE4A5KaWnc++7RsTxKaUn855OUmY2V9cyeepTVNfW87PLj6dv19KsI0mSJKkZ7c94sinA1ibvt+a2SWqjauoa+NRPZ7FgzTZuvGQch/TrknUkSZIkNbP9muAmpZRefZNSamD/nnWU1AqllPjqb57nr/PW8fX3H8VJI3tnHUmSJEkZ2J+yuCAiPhsRxbmvzwEL9ufkETEhIl6KiHkR8ZU97B8SEQ9HxOyIeC4izs9tHxoROyLimdzXj5t8ZlxEPJ875w8iNy1jRPSMiIci4pXcn64WLr0FP/jTPH45axmfO3sUHxg3KOs4kiRJysj+lMWrgJOA5bmv44Er3uhDEVEI/AiYCIwGLo6I0bscdi1wT0rpGOAi4IYm++anlMbmvq5qsn0K8ElgVO5rQm77V4A/pZRGAX/KvZf0Jvxq1jK++8eXed+xA/n8OaOyjiNJkqQMvWFZTCmtTildlFLqm/v6SEpp9X6c+zhgXkppQUqpBrgbuGDX0wNdc6+7ASv2dcKIGAB0TSn9LTc09nYal/Igd+7bcq9va7Jd0n54fP5avvLr5zhpRC++/r6jXEtRkiSpndtrWYyIT0bEqNzriIhbI2JTbrjosftx7oHA0ibvl+W2NXUdcElELAPuAz7TZN+w3PDURyLi1CbnXLaXc/ZLKa3Mva4C+u1HRknAK6u2cOUdsxjaq4wpl4yjpMi1FCVJktq7ff1G+DlgUe71xcDRwHDgH4DvH6DvfzEwLaU0CDgfuCMiCoCVwJDc8NR/AO6MiK77OM/r5O46pj3ti4grIqIiIirWrFnz9q9AauVWb6lm0tSZlBYXMnXyeLp1LM46kiRJklqAfZXFupRSbe71u4DbU0rrUkp/BMr249zLgcFN3g/KbWvqMuAegJTSE0Ap0DultDOltC63fRYwHzgk9/mmM240Peeq3DDVV4er7nGobErpppRSeUqpvE+fPvtxGVLbtb2mjsumVbB+Ww0/ubScQT06ZR1JkiRJLcS+ymJDRAyIiFLgbOCPTfZ13I9zzwRGRcSwiCihcQKbe3c5Zknu3ETE4TSWxTUR0Sc3QQ4RMZzGiWwW5IaZbo6IE3KzoH4c+F3uXPcCl+ZeX9pku6Q9qG9IfPau2cxZsYn/vfgYjhrUPetIkiRJakH2tV7ivwEVQCFwb0ppDkBEnM5+LJ2RUqqLiGuAB3LnuDWlNCcirgcqUkr3Al8Ebo6IL9A4bHRSSilFxGnA9RFRCzQAV6WU1udOfTUwjcbCOj33BfB14J6IuAxYDHxof/9HkNqblBLX/34Of3xhNddfcATnjPYRX0mSJL1eND7et5edEUVAl5TShibbynKf29oM+fKqvLw8VVRUZB1Dana3PLaA//zDC3zy1GH8yzt3XdFGkiRJ7UVEzEople9p377uLJJSqgM27LJt2wHMJqmZ3V+5kv+67wUmjunPP088POs4kiRJaqGcH19qR55esoHP3f0MYwd357sfHktBgWspSpIkac8si1I7sXjdNj55WwX9upZyy8fLKS0uzDqSJEmSWrC3VBYj4rADHURS/mzcXsPkqTOpT4lpk8fTq3OHrCNJkiSphXurdxYfPKApJOVNdW09V9w+i2UbdnDzx8sZ3qdz1pEkSZLUCux1gpuI+MHedgHd85JG0gHV0JD40i+f46lF6/nBxccwfmjPrCNJkiSpldjXbKiTaVwHcece9l2cnziSDqRvPfgSv392Bf804VDec/RBWceRJElSK7KvsjgTqEwpPb7rjoi4Lm+JJB0Qdz21hBtmzOfi44bwqdNHZB1HkiRJrcy+yuIHgOo97UgpDctPHEkHwiMvr+Ha31Zy+iF9+I8LjiDCJTIkSZL05uxrgpvOKaXtzZZE0gExd8Vmrv7pLA7p14UfffRYigpdIUeSJElv3r5+i/ztqy8i4lf5jyLp7Vq5aQefmDaTLqXFTJ00ns4d9jV4QJIkSdq7ff0m2XTc2vB8B5H09myprmXy1Jls3VnHL646kf7dSrOOJEmSpFZsX2Ux7eW1pBamtr6BT985m1dWb2XqpPEcPqBr1pEkSZLUyu2rLB4dEZtpvMPYMfea3PuUUvK3UakFSCnxr7+t5NGX1/CN9x/JaYf0yTqSJEmS2oC9lsWUUmFzBpH01twwYz53z1zKNWeO5MPjh2QdR5IkSW2E0yRKrdjvnlnO/zzwEheMPYgvnndI1nEkSZLUhlgWpVbqyQXr+NIvnuO4YT355geOci1FSZIkHVCWRakVmr9mK1fcMYtBPTty08fG0aHIUeOSJEk6sCyLUiuzdutOJk+dSVFBMG3ScXTvVJJ1JEmSJLVBrtgttSI7auq5/LYKVm+p5u4rTmRIr05ZR5IkSVIbZVmUWon6hsTnfz6bZ5dtZMpHxzF2cPesI0mSJKkNcxiq1Er8930v8MCcVVz7ztFMGNM/6ziSJElq4yyLUitw2+OLuOUvC5l00lAuO2VY1nEkSZLUDlgWpRbuobmr+Nrv53Du6H7867tGZx1HkiRJ7YRlUWrBnlu2kc/eNZsjB3bj+xeNpbDAtRQlSZLUPCyLUgu1dP12PjGtgl6dS7jl0vF0KnE+KkmSJDUff/uUWqBNO2qZPG0mNXX13H3F8fTp0iHrSJIkSWpnLItSC1NT18BVd8xi8bpt3P6J4xnZt0vWkSRJktQOWRalFiSlxFd+9RxPLFjHdz98NCeO6JV1JEmSJLVTPrMotSDf/eMr/Hr2cr547iG895hBWceRJElSO2ZZlFqIX1Qs5Qd/eoUPjhvENWeNzDqOJEmS2jnLotQC/HXeWv75189zysje/L/3HUmES2RIkiQpW5ZFKWMvVW3hqjtmMaJPZ2645FiKC/3HUpIkSdnzt1IpQ6s2VzN56lN0LCnk1snj6VpanHUkSZIkCXA2VCkz23bWcdltM9m4o5Z7rjyRgd07Zh1JkiRJeo13FqUM1NU38Jm7ZjN3xWZ+9JFjGTOwW9aRJEmSpNfxzqLUzFJKXPf7Ofz5xdX854VjOPOwvllHkiRJknbjnUWpmd382AJ++rclXHn6cC454eCs40iSJEl7ZFmUmtEfnlvJ/7vvRd555AC+/I7Dso4jSZIk7ZVlUWomsxav5wv3PMO4g3vw7Q8dTUGBaylKkiSp5bIsSs1g0dptXH5bBQd1K+Xmj5dTWlyYdSRJkiRpn/JaFiNiQkS8FBHzIuIre9g/JCIejojZEfFcRJy/h/1bI+Ifc+8PjYhnmnxtjojP5/ZdFxHLm+w7f9fvJ2Vh/bYaJk19CoBpk4+jZ1lJxokkSZKkN5a32VAjohD4EXAusAyYGRH3ppTmNjnsWuCelNKUiBgN3AcMbbL/O8D0V9+klF4CxjY5/3LgN02O/25K6VsH/mqkt6a6tp4rbq9gxaZq7vrk8QztXZZ1JEmSJGm/5PPO4nHAvJTSgpRSDXA3cMEuxySga+51N2DFqzsi4kJgITBnL+c/G5ifUlp8IENLB0pDQ+KLv3iWisUb+O6HxjLu4J5ZR5IkSZL2Wz7L4kBgaZP3y3LbmroOuCQiltF4V/EzABHRGfgy8LV9nP8i4K5dtl2TG856a0T0eBvZpbftGw+8yB+eW8k/TzyMdx41IOs4kiRJ0puS9QQ3FwPTUkqDgPOBOyKigMYS+d2U0tY9fSgiSoD3AL9osnkKMILGYaorgW/v5bNXRERFRFSsWbPmQF2H9Do//dtibnxkAZecMIQrThuedRxJkiTpTcvbM4s0Pk84uMn7QbltTV0GTABIKT0REaVAb+B44AMR8U2gO9AQEdUppR/mPjcReDqltOrVEzV9HRE3A/+3p1AppZuAmwDKy8vTW746aS8efnE1//a7Ss46rC/XvfsIIlwiQ5IkSa1PPsviTGBURAyjsSReBHxkl2OW0Pjs4bSIOBwoBdaklE599YCIuA7Y2qQoQuMdydcNQY2IASmllbm37wUqD+C1SPulcvkmPn3n0xw+oCv/e/ExFBVmffNekiRJemvyVhZTSnURcQ3wAFAI3JpSmhMR1wMVKaV7gS8CN0fEF2ic7GZSSmmfd/sioozGGVav3GXXNyNibO48i/awX8qrFRt38IlpM+nesZhbJ42nrEM+/y5GkiRJyq94g27WppWXl6eKioqsY6gN2FxdywenPMGKjTv45adO4tD+XbKOJEmSJL2hiJiVUirf0z5vfUhvU219A1f/9Gnmr9nKtMnHWRQlSZLUJlgWpbchpcS//OZ5/jJvLf/zgaM4ZVTvrCNJkiRJB4Szb0hvww//PI97Kpbx2bNH8cHywW/8AUmSJKmVsCxKb9FvZi/j2w+9zPuOGcgXzhmVdRxJkiTpgLIsSm/BE/PX8U+/fI4Thvfk6+8/yrUUJUmS1OZYFqU3ad7qLVx5RwUH9yrjxkvKKSnyHyNJkiS1Pf6WK70Ja7bsZNLUmZQUFTJ10ni6dSrOOpIkSZKUF5ZFaT9tr6nj8ttmsm5rDbdOKmdwz05ZR5IkSZLyxqUzpP1Q35D43N3P8NzyTdz0sXKOGtQ960iSJElSXnlnUdoP//F/c3lo7ir+/V2jOXd0v6zjSJIkSXlnWZTewK1/Wci0xxdx2SnDmHTysKzjSJIkSc3CsijtwwNzqviPP8zlHUf046vnH551HEmSJKnZWBalvXhm6UY+d/dsjh7Une99+BgKC1xLUZIkSe2HZVHagyXrtnPZtJn06dKBWy4tp2NJYdaRJEmSpGZlWZR2sXF7DZOmPUVdQ2La5OPo3blD1pEkSZKkZmdZlJrYWVfPFXfMYtn6Hdz0sXGM6NM560iSJElSJlxnUcpJKfFPv3yOpxau5/sXjeX44b2yjiRJkiRlxjuLUs63H3yZ3z2zgi+941AuGDsw6ziSJElSpiyLEvDzmUv44cPzuGj8YK4+Y0TWcSRJkqTMWRbV7j368hq++ptKTjukD/9x4RgiXCJDkiRJsiyqXXth5Wau/tnTjOrbmR995BiKC/1HQpIkSQLLotqxqk3VfGLaTDp3KGLq5PF0KS3OOpIkSZLUYlgW1S5t3VnH5Gkz2byjllsnjWdAt45ZR5IkSZJaFJfOULtTV9/Ap3/2NC+v2sJPLi1n9EFds44kSZIktTjeWVS7klLiX383h0deXsN/XjiGMw7tm3UkSZIkqUWyLKpd+fEjC7jrqSVcfcYILj5uSNZxJEmSpBbLsqh24/fPruAb97/Iu48+iH8879Cs40iSJEktmmVR7cLMRev54j3PctzQnnzrg0dRUOBaipIkSdK+WBbV5i1Ys5VP3l7BoB4dufFj4+hQVJh1JEmSJKnFsyyqTVu3dSeTps6kMIKpk8fTo6wk60iSJElSq+DSGWqzqmvrufz2ClZtruauK07g4F5lWUeSJEmSWg3LotqkhobEF37+DM8s3ciUjx7LsUN6ZB1JkiRJalUchqo26b+nv8D0yir+5fzDmTBmQNZxJEmSpFbHsqg25/YnFnHzYwu59MSDueyUYVnHkSRJkloly6LalD/OXcV1987hnMP78m/vPoIIl8iQJEmS3grLotqM55dt4jN3zeaIg7rxg4uPodC1FCVJkqS3zLKoNmHZhu184raZ9Cwr4SeTyulU4txNkiRJ0tvhb9Rq9TbtqGXy1JlU19bzs8uPp2+X0qwjSZIkSa2edxbVqtXUNfCpn85i0bpt3HjJOA7p1yXrSJIkSVKb4J1FtVopJf7518/z+Px1fPuDR3PSyN5ZR5IkSZLaDO8sqtX6/p9e4VdPL+ML5xzC+8cNyjqOJEmS1KbktSxGxISIeCki5kXEV/awf0hEPBwRsyPiuYg4fw/7t0bEPzbZtigino+IZyKiosn2nhHxUES8kvuzRz6vTdn65axlfO+Pr/D+Ywfx2bNHZh1HkiRJanPyVhYjohD4ETARGA1cHBGjdznsWuCelNIxwEXADbvs/w4wfQ+nPzOlNDalVN5k21eAP6WURgF/yr1XG/T4vLV85VfPcdKIXvz3+450LUVJkiQpD/J5Z/E4YF5KaUFKqQa4G7hgl2MS0DX3uhuw4tUdEXEhsBCYs5/f7wLgttzr24AL31JqtWgvr9rClT+dxfA+ZUy5ZBwlRY6kliRJkvIhn79pDwSWNnm/LLetqeuASyJiGXAf8BmAiOgMfBn42h7Om4AHI2JWRFzRZHu/lNLK3OsqoN/bvgK1KKu3VDN56kxKiwu5ddJ4unUszjqSJEmS1GZlfVvmYmBaSmkQcD5wR0QU0Fgiv5tS2rqHz5ySUjqWxuGtn46I03Y9IKWUaCyVu4mIKyKiIiIq1qxZc6CuQ3m2bWcdl02rYMP2GqZOGs+gHp2yjiRJkiS1afksi8uBwU3eD8pta+oy4B6AlNITQCnQGzge+GZELAI+D3w1Iq7JHbc89+dq4Dc0DncFWBURAwByf67eU6iU0k0ppfKUUnmfPn3e5iWqOdQ3JD5712zmrNjE/158DGMGdss6kiRJktTm5bMszgRGRcSwiCihcQKbe3c5ZglwNkBEHE5jWVyTUjo1pTQ0pTQU+B7w/1JKP4yIsojokju+DDgPqMyd617g0tzrS4Hf5e3K1GxSSnzt93P404ur+dp7juDswx1dLEmSJDWHonydOKVUl7sb+ABQCNyaUpoTEdcDFSmle4EvAjdHxBdoHDY6KTeEdG/6Ab/JzX5ZBNyZUro/t+/rwD0RcRmwGPhQXi5Mzeonf1nI7U8s5orThvOxE4dmHUeSJElqN2Lf3axtKy8vTxUVFW98oDIx/fmVXH3n00wc058fXnwsBQUukSFJkiQdSBExa5clCV+T9QQ30h7NWryBz//8GY4Z3J3vfGisRVGSJElqZpZFtTiL123jk7dX0L9bKTd/vJzS4sKsI0mSJEntjmVRLcqGbTVMmjqThpSYOmk8vTp3yDqSJEmS1C7lbYIb6c2qrq3nijsqWL5xB3defjzD+3TOOpIkSZLUbnlnUS1CQ0PiS798jpmLNvDtDx5N+dCeWUeSJEmS2jXLolqE/3nwJX7/7Aq+MvEw3n30QVnHkSRJkto9y6Iyd+eTS5gyYz4fOX4IV542POs4kiRJkrAsKmMPv7Saf/1dJWcc2ofr33MEES6RIUmSJLUElkVlZs6KTVzzs6c5tF8XfviRYykq9MdRkiRJain87VyZWLlpB5+YNpOuHYuZOnk8nTs4Ma8kSZLUkvgbuprdlupaJk+dybad9fzyUyfSr2tp1pEkSZIk7cI7i2pWtfUNXP2zp5m3eitTLjmWw/p3zTqSJEmSpD3wzqKaTUqJa39TyWOvrOWb7z+KU0f1yTqSJEmSpL3wzqKazQ0z5vPziqV85qyRfGj84KzjSJIkSdoHy6Kaxe+eWc7/PPASF449iH8495Cs40iSJEl6A5ZF5d2TC9bxpV88x/HDevKNDxzlWoqSJElSK2BZVF7NW72VK+6YxeCeHbnpY+V0KCrMOpIkSZKk/WBZVN6s2bKTydOeorgwmDb5OLp1Ks46kiRJkqT95GyoyosdNfVcfnsFa7bs5O4rTmRwz05ZR5IkSZL0JlgWdcDVNyQ+//PZPLdsIzdeMo6xg7tnHUmSJEnSm+QwVB1w//WHF3hgzir+7V2jOe+I/lnHkSRJkvQWWBZ1QE3960Ju/etCJp88lMknD8s6jiRJkqS3yLKoA+bBOVVc/39zOW90P6595+is40iSJEl6GyyLOiCeXbqRz949m6MGduP7Fx1DYYFrKUqSJEmtmWVRb9vS9du57LaZ9OnSgVsuHU/HEtdSlCRJklo7y6Lelk3ba5k8bSY1dQ1MnXQcfbp0yDqSJEmSpAPApTP0lu2sq+fKn1aweN027rjseEb27Zx1JEmSJEkHiGVRb0lKia/86nn+tmA93/vwWE4Y3ivrSJIkSZIOIIeh6i357kMv85vZy/nH8w7hwmMGZh1HkiRJ0gFmWdSbdk/FUn7w53l8uHwwnz5zZNZxJEmSJOWBZVFvyl9eWctXf/08p47qzX++dwwRLpEhSZIktUWWRe23F6s286mfzmJk38786KPHUlzoj48kSZLUVvnbvvbLqs3VfGLqTDp1KOTWSePpWlqcdSRJkiRJeWRZ1BvaurOOyVNnsmlHLbdOGs9B3TtmHUmSJElSnrl0hvaprr6Bz9z5NC+t2sItl5ZzxEHdso4kSZIkqRl4Z1F7lVLi3++dw8MvreH6C47gzEP7Zh1JkiRJUjOxLGqvbnp0AT97cglXnT6Cjx5/cNZxJEmSJDUjy6L26P+eW8F/T3+Rdx01gH96x6FZx5EkSZLUzCyL2k3FovX8wz3PUn5wD771waMpKHAtRUmSJKm9sSzqdRau3cYnb69gYPeO3PTxckqLC7OOJEmSJCkDlkW9Zv22GiZPfYqIYOqk8fQsK8k6kiRJkqSM5LUsRsSEiHgpIuZFxFf2sH9IRDwcEbMj4rmIOH8P+7dGxD/m3g/OHT83IuZExOeaHHtdRCyPiGdyX+fv+v20d9W19Vx+20xWbKrm5o+XM7R3WdaRJEmSJGUob+ssRkQh8CPgXGAZMDMi7k0pzW1y2LXAPSmlKRExGrgPGNpk/3eA6U3e1wFfTCk9HRFdgFkR8VCTc343pfStPF1Sm9XQkPjiPc8ye+lGfvSRYxl3cI+sI0mSJEnKWD7vLB4HzEspLUgp1QB3AxfsckwCuuZedwNWvLojIi4EFgJzXjs4pZUppadzr7cALwAD83UB7cU37n+RPzy/kq9OPJzzjxyQdRxJkiRJLUA+y+JAYGmT98vYvdhdB1wSEctovKv4GYCI6Ax8Gfja3k4eEUOBY4Anm2y+Jjec9daI8PbYfrjjb4u58dEFfOyEg7n81GFZx5EkSZLUQmQ9wc3FwLSU0iDgfOCOiCigsUR+N6W0dU8fypXJXwGfTyltzm2eAowAxgIrgW/v5bNXRERFRFSsWbPmQF5Lq/PnF1fx77+r5KzD+vLv7x5NhEtkSJIkSWqUt2cWgeXA4CbvB+W2NXUZMAEgpfRERJQCvYHjgQ9ExDeB7kBDRFSnlH4YEcU0FsWfpZR+/eqJUkqrXn0dETcD/7enUCmlm4CbAMrLy9PbusJWrHL5Jq65czajD+rK/158DEWFWf+9gSRJkqSWJJ9lcSYwKiKG0VgSLwI+sssxS4CzgWkRcThQCqxJKZ366gERcR2wNVcUA/gJ8EJK6TtNTxQRA1JKK3Nv3wtU5uGa2oTlG3cwedpMenQq4dZLx1PWIZ8/BpIkSZJao7y1hJRSXURcAzwAFAK3ppTmRMT1QEVK6V7gi8DNEfEFGie7mZRS2tfdvpOBjwHPR8QzuW1fTSndB3wzIsbmzrMIuDIPl9Xqba6uZfLUp6iuqednVx9P366lWUeSJEmS1ALFvrtZ21ZeXp4qKiqyjtFsauoamDztKZ5csJ7bPnEcJ4/snXUkSZIkSRmKiFkppfI97XP8YTuRUuKrv3mev85bx7c+eLRFUZIkSdI+OatJO/G/f57HL2ct43Nnj+ID4wZlHUeSJElSC2dZbAd+/fQyvvPQy7zv2IF8/pxRWceRJEmS1ApYFtu4x+ev5cu/eo4Th/fi6+87yrUUJUmSJO0Xy2Ib9sqqLVx5xyyG9irjxx8bR0mR/3dLkiRJ2j+2hzZq9ZZqJk2dSYeiQm6dNJ5uHYuzjiRJkiSpFbEstkHba+q4/LYK1m+r4dZJ5Qzu2SnrSJIkSZJaGctiG1PfkPjsXbOpXL6J/734GI4a1D3rSJIkSZJaIddZbENSSlz/+zn88YXVXH/BEZwzul/WkSRJkiS1Ut5ZbENu/esibntiMZefMoyPnzg06ziSJEmSWjHLYhtxf+VK/vMPc5lwRH++ev7hWceRJEmS1MpZFtuA2Us28Lm7n2Hs4O5876KxFBS4lqIkSZKkt8ey2MotWbedy2+roF/XUm7+eDmlxYVZR5IkSZLUBlgWW7GN22uYNO0p6lNi2uTx9O7cIetIkiRJktoIy2IrtbOunitun8Wy9Tu46WPlDO/TOetIkiRJktoQl85ohRoaEl/6xXM8tWg9P7j4GI4b1jPrSJIkSZLaGO8stkLffugl7n12Bf804VDec/RBWceRJEmS1AZZFluZu59awo8ens/Fxw3mU6ePyDqOJEmSpDbKstiKPPLyGv7lt5Wcfkgf/uOCMUS4RIYkSZKk/LAsthJzV2zm0z97mkP6deFHHz2WokL/r5MkSZKUPzaOVmDlph18YtpMOnco4tZJ5XTu4LxEkiRJkvLL1tHCbamuZfLUmWzdWccvrjqRAd06Zh1JkiRJUjtgWWzBausb+PSds3ll9VZunTSewwd0zTqSJEmSpHbCYagtVEqJf/tdJY++vIb/unAMpx/SJ+tIkiRJktoRy2ILNeWR+dz11FI+feYILjpuSNZxJEmSJLUzlsUW6HfPLOeb97/Ee44+iC+ee2jWcSRJkiS1Q5bFFuaphev50i+e47ihPfmfDx5FQYFrKUqSJElqfpbFFubOJxczqGdHbvr4ODoUFWYdR5IkSVI75WyoLcy3Png067fX0L1TSdZRJEmSJLVj3llsYYoKC+jbpTTrGJIkSZLaOcuiJEmSJGk3lkVJkiRJ0m4si5IkSZKk3VgWJUmSJEm7sSxKkiRJknZjWZQkSZIk7cayKEmSJEnajWVRkiRJkrQby6IkSZIkaTeWRUmSJEnSbiyLkiRJkqTd5LUsRsSEiHgpIuZFxFf2sH9IRDwcEbMj4rmIOH8P+7dGxD++0TkjYlhEPJnb/vOIKMnntUmSJElSW5a3shgRhcCPgInAaODiiBi9y2HXAveklI4BLgJu2GX/d4Dp+3nObwDfTSmNBDYAlx3YK5IkSZKk9iOfdxaPA+allBaklGqAu4ELdjkmAV1zr7sBK17dEREXAguBOW90zogI4Czgl7njbgMuPKBXI0mSJEntSD7L4kBgaZP3y3LbmroOuCQilgH3AZ8BiIjOwJeBr+3nOXsBG1NKdfv4XpIkSZKk/ZT1BDcXA9NSSoOA84E7IqKAxhL53ZTS1gP9DSPiioioiIiKNWvWHOjTS5IkSVKbUJTHcy8HBjd5Pyi3ranLgAkAKaUnIqIU6A0cD3wgIr4JdAcaIqIamLWXc64DukdEUe7u4p6+F7nvcxNwE0BErImIxW/nIvOkN7A26xBSM/PnXu2VP/tqj/y5V3vUUn/uD97bjnyWxZnAqIgYRmNxuwj4yC7HLAHOBqZFxOFAKbAmpXTqqwdExHXA1pTSDyOiaE/nTCmliHgY+ACNzzFeCvzujQKmlPq8zWvMi4ioSCmVZ51Dak7+3Ku98mdf7ZE/92qPWuPPfd6Goebu8F0DPAC8QOOsp3Mi4vqIeE/usC8Cn4yIZ4G7gEkppfRmz5nb/WXgHyJiHo3PMP4kH9clSZIkSe1B7KObKSOt8W8dpLfLn3u1V/7sqz3y517tUWv8uc96ghvt2U1ZB5Ay4M+92it/9tUe+XOv9qjV/dx7Z1GSJEmStBvvLEqSJEmSdmNZbEEi4taIWB0RlVlnkZpLRAyOiIcjYm5EzImIz2WdScq3iCiNiKci4tncz/3Xss4kNZeIKIyI2RHxf1lnkZpLRCyKiOcj4pmIqMg6z/5yGGoLEhGnAVuB21NKY7LOIzWHiBgADEgpPR0RXWhcT/XClNLcjKNJeRMRAZSllLZGRDHwF+BzKaW/ZRxNyruI+AegHOiaUnpX1nmk5hARi4DylFJLXGdxr7yz2IKklB4F1medQ2pOKaWVKaWnc6+30LgszsBsU0n5lRptzb0tzn35t7dq8yJiEPBO4Jass0h6Y5ZFSS1GRAwFjgGezDiKlHe5oXjPAKuBh1JK/tyrPfge8E9AQ8Y5pOaWgAcjYlZEXJF1mP1lWZTUIkREZ+BXwOdTSpuzziPlW0qpPqU0FhgEHBcRPn6gNi0i3gWsTinNyjqLlIFTUkrHAhOBT+ceP2vxLIuSMpd7ZutXwM9SSr/OOo/UnFJKG4GHgQkZR5Hy7WTgPblnt+4GzoqIn2YbSWoeKaXluT9XA78Bjss20f6xLErKVG6ij58AL6SUvpN1Hqk5RESfiOiee90ROBd4MdNQUp6llP45pTQopTQUuAj4c0rpkoxjSXkXEWW5SfyIiDLgPKBVrH5gWWxBIuIu4Ang0IhYFhGXZZ1JagYnAx+j8W+Yn8l9nZ91KCnPBgAPR8RzwEwan1l0GQFJapv6AX+JiGeBp4A/pJTuzzjTfnHpDEmSJEnSbryzKEmSJEnajWVRkiRJkrQby6IkSZIkaTeWRUmSJEnSbiyLkiRJkqTdWBYlSZIkSbuxLEqSJEmSdmNZlCRJkiTt5v8Djzuvkj7cWooAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F1 Score at Epoch 4: 0.8594395326314473\n"
     ]
    }
   ],
   "source": [
    "#Plotting F1 Scores\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plt.plot(RANGE, val_F1)\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(RANGE)\n",
    "plt.savefig('NoisyF1Plot.png')\n",
    "plt.show()\n",
    "max_value = max(val_F1)\n",
    "max_index = val_F1.index(max_value) + 1\n",
    "print(f\"Max F1 Score at Epoch {max_index}: {max_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf024b5c",
   "metadata": {},
   "source": [
    "# Epoch 4 performs the best so we will be using the model from epoch 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40fb79b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 14908\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='466' max='466' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [466/466 00:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#step no 160500\n",
    "predictions = trainer.predict(full_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8eb56cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 1.2844193 , -1.2373391 ],\n",
      "       [ 0.34289253, -0.35211933],\n",
      "       [-2.9895635 ,  2.7084394 ],\n",
      "       ...,\n",
      "       [-1.735612  ,  1.6335813 ],\n",
      "       [ 1.5382487 , -1.4909675 ],\n",
      "       [ 0.46275756, -0.44103575]], dtype=float32), label_ids=array([1, 0, 1, ..., 1, 1, 0]), metrics={'test_loss': 0.42401960492134094, 'test_accuracy': 0.8127850818352562, 'test_recall': 0.8489385898407885, 'test_precision': 0.8821270310192023, 'test_f1': 0.865214661708601, 'test_runtime': 52.1867, 'test_samples_per_second': 285.667, 'test_steps_per_second': 8.929})\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2c190df",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = predictions.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0657498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_val = np.argmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b07d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e42bb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is: \n",
      "\n",
      "[[3159 1197]\n",
      " [1594 8958]]\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(true_vals,predicted_val)\n",
    "print(\"Confusion matrix is: \\n\")\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4418ad4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x540 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "cf_matrix = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "plt.savefig('NoisyConfusionPlot.png')\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5a4763",
   "metadata": {},
   "source": [
    "# So the accuracy of the model is 0.8127850818352562 and F1 score is 0.865214661708601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5acfc4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 score is : \n",
      " \n",
      "0.815070134333853\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted F1 score is : \\n \")\n",
    "print(f1_score(true_vals,predicted_val,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b801473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict = {'Negative' : 0 , 'Positive' : 1}\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    #make prediction\n",
    "    preds_flat = preds.flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "    \n",
    "    print(f'Total accuracy is : {accuracy_score(labels_flat,preds_flat)}\\n')\n",
    "    \n",
    "    return accuracy_score(labels_flat,preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0bd6d20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Negative\n",
      "Accuracy:3159/4356\n",
      "\n",
      "Class: Positive\n",
      "Accuracy:8958/10552\n",
      "\n",
      "Total accuracy is : 0.8127850818352562\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8127850818352562"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_per_class(predicted_val, true_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
