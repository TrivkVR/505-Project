{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258b605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from transformers import pipeline, BertTokenizer, BertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import f1_score\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "\n",
    "def preprocessing(tweet):\n",
    "    temp = tweet.lower()\n",
    "    temp = re.sub('@[A-Za-z]+[A-Za-z0-9-_]+', ' ', temp)\n",
    "    temp = re.sub(r'https\\S+', '', temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub(\"[0-9]\", \" \", temp)\n",
    "    temp = re.sub(\"\\s\\s+\", \" \", temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82927815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-5\n",
    "SEED = 4222\n",
    "\n",
    "MODEL_SAVE_PATH = \"Model_4/electra\"\n",
    "MODEL_CHECKPOINT_PATH = \"Model_4/electra_checkpoint\"\n",
    "MODEL_LOGGING_PATH = \"Model_4/electra_checkpoint/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8330a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    6935\n",
      "0    2420\n",
      "Name: label, dtype: int64\n",
      "0    6935\n",
      "1    6935\n",
      "Name: label, dtype: int64\n",
      "['theo walcott is still shit\\\\u c watch rafa and johnny deal with him on saturday.', 'its not that i\\\\u m a gsp fan\\\\u c i just hate nick diaz. can\\\\u t wait for february.', 'iranian general says israel\\\\u s iron dome can\\\\u t deal with their missiles (keep talking like that and we may end up finding out)', 'with j davlar th. main rivals are team poland. hopefully we an make it a successful end to a tough week of training tomorrow.', 'talking about act\\\\u s && sat\\\\u s\\\\u c deciding where i want to go to college\\\\u c applying to colleges and everything about college stresses me out.', 'they may have a superbowl in dallas\\\\u c but dallas ain\\\\u t winning a superbowl. not with that quarterback and owner. ', ' i just watched it! sridevi\\\\u s comeback.... u remember her from the s?? sun mornings on nta ;)', 'one of my best th graders kory was excited after his touchdown today!! he did the victor cruz!!lol ', ' i didnt want to just pop up... but yep we have chapel hill next wednesday you should come.. and shes great ill tell her you asked', ' serge is amazing... like hes actually a god the lanky sex god... i saw kasabian and noel together in august. it was amazing.']\n"
     ]
    }
   ],
   "source": [
    "#oversampling since there are much less negative sentiment tweets than positive or neutral\n",
    "oversample = RandomOverSampler(sampling_strategy='minority', random_state = 17)\n",
    "\n",
    "full_training_data = pd.read_csv('full_training_data_noneutral.csv')\n",
    "X_training_data_imb2 = pd.read_csv('full_training_data_noneutral.csv', usecols = [2])\n",
    "Y_training_data_imb2 = pd.read_csv('full_training_data_noneutral.csv', usecols = [3])\n",
    "\n",
    "X_training_data_over, Y_training_data_over = oversample.fit_resample(X_training_data_imb2, Y_training_data_imb2)\n",
    "\n",
    "\n",
    "\n",
    "label_dict = {}\n",
    "possible_labels = full_training_data.sentiment.unique()\n",
    "\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    "\n",
    "print(Y_training_data_imb2['label'].value_counts())\n",
    "print(Y_training_data_over['label'].value_counts())\n",
    "\n",
    "X_training_data_over2 = X_training_data_over.tweet_text\n",
    "Y_training_data_over2 = Y_training_data_over.label\n",
    "\n",
    "#preprocessing the tweets\n",
    "\n",
    "X_training_data_over2 = [preprocessing(tweet) for tweet in X_training_data_over2]\n",
    "print(X_training_data_over2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ad853cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to change between imb and over\n",
    "X_training_data_full = X_training_data_over2\n",
    "Y_training_data_full = Y_training_data_over2\n",
    "d = {'Polarity':Y_training_data_full,'text':X_training_data_full}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f08d07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('full_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9598d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ELECTRA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\", do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd3d4641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Import ELECTRA-base pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google/electra-small-discriminator\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd154253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_conversion(train, test):\n",
    "  \"\"\"Converts pandas dataframe to Dataset.\"\"\"\n",
    "\n",
    "  train.reset_index(drop=True, inplace=True)\n",
    "  test.reset_index(drop=True, inplace=True)\n",
    "#   val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "  train_dataset = Dataset.from_pandas(train)\n",
    "  test_dataset = Dataset.from_pandas(test)\n",
    "#   val_dataset = Dataset.from_pandas(val)\n",
    "\n",
    "  return DatasetDict({\"train\": train_dataset,\n",
    "                      \"test\": test_dataset})\n",
    "#                       \"val\": val_dataset})\n",
    "\n",
    "raw_datasets = dataset_conversion(df, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96037477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b51488b9ba476bb7c05e01d92bc89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743cca2537424567aba3fed5bd567e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(dataset):\n",
    "    return tokenizer(dataset[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb9554a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise datasets\n",
    "SAMPLE_SIZE = 20\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "# small_val_dataset = tokenized_datasets[\"val\"].shuffle(seed=SEED).select(range(SAMPLE_SIZE))\n",
    "\n",
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_test_dataset = tokenized_datasets[\"test\"]\n",
    "# full_val_dataset = tokenized_datasets[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3be4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = full_train_dataset.rename_column(\"Polarity\", \"label\")\n",
    "full_test_dataset = full_test_dataset.rename_column(\"Polarity\", \"label\")\n",
    "# full_val_dataset = full_val_dataset.rename_column(\"Polarity\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b02211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom metrics for computation\n",
    "def compute_metrics(eval_pred):\n",
    "    metric_acc = load_metric(\"accuracy\")\n",
    "    metric_rec = load_metric(\"recall\")\n",
    "    metric_pre = load_metric(\"precision\")\n",
    "    metric_f1 = load_metric(\"f1\")\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = metric_acc.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    recall = metric_rec.compute(predictions=predictions, references=labels)[\"recall\"]\n",
    "    precision = metric_pre.compute(predictions=predictions, references=labels)[\"precision\"]\n",
    "    f1 = metric_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"recall\": recall, \"precision\": precision, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "049eb6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Define model and training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_CHECKPOINT_PATH,\n",
    "    overwrite_output_dir = True,\n",
    "#     report_to = 'wandb',\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    logging_dir=MODEL_LOGGING_PATH,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=433\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_train_dataset,\n",
    "    eval_dataset=full_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbddc535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: text. If text are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr4/cs505/orawal/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 13870\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4335' max='4335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4335/4335 08:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.559600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.361400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.300900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.266200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.222200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.201200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to Model_4/electra_checkpoint/checkpoint-433\n",
      "Configuration saved in Model_4/electra_checkpoint/checkpoint-433/config.json\n",
      "Model weights saved in Model_4/electra_checkpoint/checkpoint-433/pytorch_model.bin\n",
      "tokenizer config file saved in Model_4/electra_checkpoint/checkpoint-433/tokenizer_config.json\n",
      "Special tokens file saved in Model_4/electra_checkpoint/checkpoint-433/special_tokens_map.json\n",
      "Saving model checkpoint to Model_4/electra_checkpoint/checkpoint-866\n",
      "Configuration saved in Model_4/electra_checkpoint/checkpoint-866/config.json\n",
      "Model weights saved in Model_4/electra_checkpoint/checkpoint-866/pytorch_model.bin\n",
      "tokenizer config file saved in Model_4/electra_checkpoint/checkpoint-866/tokenizer_config.json\n",
      "Special tokens file saved in Model_4/electra_checkpoint/checkpoint-866/special_tokens_map.json\n",
      "Saving model checkpoint to Model_4/electra_checkpoint/checkpoint-1299\n",
      "Configuration saved in Model_4/electra_checkpoint/checkpoint-1299/config.json\n",
      "Model weights saved in Model_4/electra_checkpoint/checkpoint-1299/pytorch_model.bin\n",
      "tokenizer config file saved in Model_4/electra_checkpoint/checkpoint-1299/tokenizer_config.json\n",
      "Special tokens file saved in Model_4/electra_checkpoint/checkpoint-1299/special_tokens_map.json\n",
      "Saving model checkpoint to Model_4/electra_checkpoint/checkpoint-1732\n",
      "Configuration saved in Model_4/electra_checkpoint/checkpoint-1732/config.json\n",
      "Model weights saved in Model_4/electra_checkpoint/checkpoint-1732/pytorch_model.bin\n",
      "tokenizer config file saved in Model_4/electra_checkpoint/checkpoint-1732/tokenizer_config.json\n",
      "Special tokens file saved in Model_4/electra_checkpoint/checkpoint-1732/special_tokens_map.json\n",
      "Saving model checkpoint to Model_4/electra_checkpoint/checkpoint-2165\n",
      "Configuration saved in Model_4/electra_checkpoint/checkpoint-2165/config.json\n",
      "Model weights saved in Model_4/electra_checkpoint/checkpoint-2165/pytorch_model.bin\n",
      "tokenizer config file saved in Model_4/electra_checkpoint/checkpoint-2165/tokenizer_config.json\n",
      "Special tokens file saved in Model_4/electra_checkpoint/checkpoint-2165/special_tokens_map.json\n",
      "Saving model checkpoint to Model_4/electra_checkpoint/checkpoint-2598\n",
      "Configuration saved in Model_4/electra_checkpoint/checkpoint-2598/config.json\n",
      "Model weights saved in Model_4/electra_checkpoint/checkpoint-2598/pytorch_model.bin\n",
      "tokenizer config file saved in Model_4/electra_checkpoint/checkpoint-2598/tokenizer_config.json\n",
      "Special tokens file saved in Model_4/electra_checkpoint/checkpoint-2598/special_tokens_map.json\n",
      "Saving model checkpoint to Model_4/electra_checkpoint/checkpoint-3031\n",
      "Configuration saved in Model_4/electra_checkpoint/checkpoint-3031/config.json\n",
      "Model weights saved in Model_4/electra_checkpoint/checkpoint-3031/pytorch_model.bin\n",
      "tokenizer config file saved in Model_4/electra_checkpoint/checkpoint-3031/tokenizer_config.json\n",
      "Special tokens file saved in Model_4/electra_checkpoint/checkpoint-3031/special_tokens_map.json\n",
      "Saving model checkpoint to Model_4/electra_checkpoint/checkpoint-3464\n",
      "Configuration saved in Model_4/electra_checkpoint/checkpoint-3464/config.json\n",
      "Model weights saved in Model_4/electra_checkpoint/checkpoint-3464/pytorch_model.bin\n",
      "tokenizer config file saved in Model_4/electra_checkpoint/checkpoint-3464/tokenizer_config.json\n",
      "Special tokens file saved in Model_4/electra_checkpoint/checkpoint-3464/special_tokens_map.json\n",
      "Saving model checkpoint to Model_4/electra_checkpoint/checkpoint-3897\n",
      "Configuration saved in Model_4/electra_checkpoint/checkpoint-3897/config.json\n",
      "Model weights saved in Model_4/electra_checkpoint/checkpoint-3897/pytorch_model.bin\n",
      "tokenizer config file saved in Model_4/electra_checkpoint/checkpoint-3897/tokenizer_config.json\n",
      "Special tokens file saved in Model_4/electra_checkpoint/checkpoint-3897/special_tokens_map.json\n",
      "Saving model checkpoint to Model_4/electra_checkpoint/checkpoint-4330\n",
      "Configuration saved in Model_4/electra_checkpoint/checkpoint-4330/config.json\n",
      "Model weights saved in Model_4/electra_checkpoint/checkpoint-4330/pytorch_model.bin\n",
      "tokenizer config file saved in Model_4/electra_checkpoint/checkpoint-4330/tokenizer_config.json\n",
      "Special tokens file saved in Model_4/electra_checkpoint/checkpoint-4330/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4335, training_loss=0.28869559212126944, metrics={'train_runtime': 536.3962, 'train_samples_per_second': 129.289, 'train_steps_per_second': 8.082, 'total_flos': 2040252091699200.0, 'train_loss': 0.28869559212126944, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4300b72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.5596,\n",
       "  'learning_rate': 8.846597462514419e-06,\n",
       "  'epoch': 0.58,\n",
       "  'step': 500},\n",
       " {'loss': 0.3614,\n",
       "  'learning_rate': 7.693194925028837e-06,\n",
       "  'epoch': 1.15,\n",
       "  'step': 1000},\n",
       " {'loss': 0.3009,\n",
       "  'learning_rate': 6.539792387543253e-06,\n",
       "  'epoch': 1.73,\n",
       "  'step': 1500},\n",
       " {'loss': 0.2662,\n",
       "  'learning_rate': 5.38638985005767e-06,\n",
       "  'epoch': 2.31,\n",
       "  'step': 2000},\n",
       " {'loss': 0.2453,\n",
       "  'learning_rate': 4.232987312572088e-06,\n",
       "  'epoch': 2.88,\n",
       "  'step': 2500},\n",
       " {'loss': 0.2222,\n",
       "  'learning_rate': 3.0795847750865054e-06,\n",
       "  'epoch': 3.46,\n",
       "  'step': 3000},\n",
       " {'loss': 0.2107,\n",
       "  'learning_rate': 1.926182237600923e-06,\n",
       "  'epoch': 4.04,\n",
       "  'step': 3500},\n",
       " {'loss': 0.2012,\n",
       "  'learning_rate': 7.727797001153404e-07,\n",
       "  'epoch': 4.61,\n",
       "  'step': 4000},\n",
       " {'train_runtime': 536.3962,\n",
       "  'train_samples_per_second': 129.289,\n",
       "  'train_steps_per_second': 8.082,\n",
       "  'total_flos': 2040252091699200.0,\n",
       "  'train_loss': 0.28869559212126944,\n",
       "  'epoch': 5.0,\n",
       "  'step': 4335}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b50355db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: Unnamed: 0, text. If Unnamed: 0, text are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 14908\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='932' max='932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [932/932 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(full_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7f64dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-1.6495962,  1.7638965],\n",
      "       [-1.6618115,  1.7538954],\n",
      "       [-2.0869374,  2.2262235],\n",
      "       ...,\n",
      "       [-2.0822341,  2.2274313],\n",
      "       [-2.0460558,  2.166389 ],\n",
      "       [ 1.4849364, -1.8358902]], dtype=float32), label_ids=array([1, 0, 1, ..., 1, 1, 0]), metrics={'test_loss': 0.3293605148792267, 'test_accuracy': 0.8946874161524014, 'test_recall': 0.8956595905989386, 'test_precision': 0.9527217741935484, 'test_f1': 0.9233098866744822, 'test_runtime': 39.8585, 'test_samples_per_second': 374.023, 'test_steps_per_second': 23.383})\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48e39fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = predictions.predictions\n",
    "predicted_val = np.argmax(logits, axis=-1)\n",
    "true_vals = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09a0848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is: \n",
      "\n",
      "[[3887  469]\n",
      " [1101 9451]]\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(true_vals,predicted_val)\n",
    "print(\"Confusion matrix is: \\n\")\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff59a9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x540 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "cf_matrix = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "plt.savefig('NoisyConfusionPlot.png')\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee287db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 score is : \n",
      " \n",
      "0.8966233537990147\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted F1 score is : \\n \")\n",
    "print(f1_score(true_vals,predicted_val,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a249df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict = {'Negative' : 0 , 'Positive' : 1}\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    #make prediction\n",
    "    preds_flat = preds.flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "    \n",
    "    print(f'Total accuracy is : {accuracy_score(labels_flat,preds_flat)}\\n')\n",
    "    \n",
    "    return accuracy_score(labels_flat,preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acfdf95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Negative\n",
      "Accuracy:3887/4356\n",
      "\n",
      "Class: Positive\n",
      "Accuracy:9451/10552\n",
      "\n",
      "Total accuracy is : 0.8946874161524014\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8946874161524014"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_per_class(predicted_val, true_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac7c5ff",
   "metadata": {},
   "source": [
    "# Final accuracy is 0.894 and weighted F1 score is 0.896"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
